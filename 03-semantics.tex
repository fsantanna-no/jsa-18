\section{Formal Semantics of \CEU}
\label{sec.sem}

We now introduce and formalize the semantics of a reduced version of \CEU,
called \emph{basic \CEU}.  Although simpler than the full language presented
in Section~\ref{sec.ceu}, basic \CEU is expressive enough to capture all the
essential characteristics of full \CEU, in particular, the stack-based
execution of internal events.  Once basic \CEU is defined, the more
elaborate constructs of full \CEU can be defined on top of it, as we will
discuss shortly.

The statements of basic \CEU are presented in Figure~\ref{fig.sem.syntax}.
In the figure, the metavariables~$v$ (ln~1, 2, 16), $e$ (ln~3--5, 10),
and~$n$ (ln~15--16) range over variable identifiers, event identifiers, and
integers.  The metavariable~$\stmt$ (ln~1, 7--13, 16--19) denotes a
statement, i.e., any of the statements of
Figure~\ref{fig.sem.syntax}---complex statements are defined recursively in
terms of simpler statements.  Finally, the metavariable $\expr$ (ln~2, 7)
denotes an expression.

\begin{figure}[ht!]
\begingroup
\setlength{\jot}{0pt}
\def\N#1{\mathllap{\text{\scriptsize{#1}}\hspace{1em}}}
\begin{empheq}[box=\fbox]{alignat*=3}
     \N1&\hskip4pt&&\ceu{\Var{v\,\stmt}}
                                    &\quad&\text{\it variable declaration}\\
     \N2&&&\ceu{v\coloneqq\expr}         &&\text{\it assignment statement}\\
     \N3&&&\ceu{\AwaitExt(e)}            &&\text{\it await external event}\\
     \N4&&&\ceu{\AwaitInt(e)}            &&\text{\it await internal event}\\
     \N5&&&\ceu{\EmitInt(e)}             &&\text{\it emit internal event}\\
     \N6&&&\ceu{\Break}                  &&\text{\it loop escape}\\
     \N7&&&\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}} &&\text{\it conditional}\\
     \N8&&&\ceu{\stmt_1\,;\,\stmt_2}     &&\text{\it sequence}\\
     \N9&&&\ceu{\Loop \stmt}             &&\text{\it infinite loop}\\
  \N{10}&&&\ceu{\Every{e}\,\stmt}        &&\text{\it event iteration}\\
  \N{11}&&&\ceu{\stmt_1\ParAnd\stmt_2}   &&\text{\it par/and statement}\\
  \N{12}&&&\ceu{\stmt_1\ParOr\stmt_2}    &&\text{\it par/or statement}\\
  \N{13}&&&\ceu{\Fin\stmt}               &&\text{\it finalization statement}\\
  \N{14}&&&\ceu{\Nop}                    &&\text{\it dummy statement}\\
  \N{15}&&&\ceu{\RunAt(n)}               &&\text{\it run at stack level~$n$}\\
  \N{16}&&&\ceu{\AtVar{v\,n\,\stmt}}     &&\text{\it expanded var}\\
  \N{17}&&&\ceu{\stmt_1\AtLoop\stmt_2}   &&\text{\it expanded loop}\\
  \N{18}&&&\ceu{\stmt_1\AtParAnd\stmt_2} &&\text{\it expanded par/and}\\
  \N{19}&&&\ceu{\stmt_1\AtParOr\stmt_2}  &&\text{\it expanded par/or}
\end{empheq}
\endgroup
\caption{The statements of basic \CEU.}
\label{fig.sem.syntax}
\end{figure}

For simplicity, we only consider integer expressions.  These are build up
from integer constants and variables by the usual mathematical operators
($+$, $-$, $\le$, \ldots).  We assume that expression evaluation takes zero
time (in accordance with the synchronous hypothesis) and that it always
produces an integer value.  In places where a boolean value is expected, any
nonzero value means true while zero means false.

We distinguish between three kinds of basic \CEU statements.  First, there
are those statements which are common in imperative languages and behave as
usual, namely, declarations, assignments, conditionals, sequences, loops,
and breaks.  The $\ceu{\Var}$ statement of basic \CEU introduces a single
local variable whose scope is the statement immediately following it.

The statements of the second kind are those which are specific to \CEU.
These are the statements $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\EmitInt}$, and $\ceu{\Every}$, which deal with events, the statements
$\ceu{\ParAnd}$ and~$\ceu{\ParOr}$, which define parallel compositions, and
the statement~$\ceu{\Fin}$, which defines a finalization block.  These basic
\CEU statements are more or less equivalent to their counterparts in full
\CEU.  We defer a precise description of their behavior and entailed
properties to Section~\ref{sec.sem.opsem}.

Finally, the statements of the third kind are the remaining ones, namely,
$\ceu{\Nop}$, $\ceu{\RunAt}$, $\ceu{\AtVar}$, $\ceu{\AtLoop}$,
$\ceu{\AtParAnd}$, and $\ceu{\AtParOr}$.  These are hidden internal
statements used by the interpreter to encode in the program's text
information about its execution.  We will have more to say about these
\texttt{@}-statements in Section~\ref{sec.sem.opsem}.  Before that, however,
we need to present the syntactic restrictions of basic \CEU and discuss
the mapping of full \CEU programs into basic \CEU programs.

\subsection{Syntactic Restrictions of Basic \CEU}
\label{sec.sem.restrictions}

The syntax of basic \CEU shown in Figure~\ref{fig.sem.syntax} can be seen as
a schema for generating programs.  Not all programs generated by this schema
are well-formed though.  To be considered a \emph{well-formed} basic \CEU
program, the generated program must satisfy the following restrictions:
\begin{enumerate}
\item\label{sec.sem.restrictions.1} If variable~$v$ occurs in an expression
  or assignment statement of the program, then this occurrence happens in
  the body of a~$\ceu{\Var}$ statement that declares~$v$.
\item\label{sec.sem.restrictions.2} If a~$\ceu{\Break}$ occurs in the
  program, then this occurrence happens in the body of a~$\ceu{\Loop}$.
\item\label{sec.sem.restrictions.3} If a statement of the
  form~$\ceu{\Loop{\stmt}}$ occurs in the program, then all execution paths
  within~$\stmt$ contain a matching~$\ceu{\Break}$ or an~$\ceu{\AwaitExt}$
  or an~$\ceu{\EveryExt}$ (i.e., an $\ceu{\Every}$ that expects an external
  event.)
\item\label{sec.sem.restrictions.4} If a statement of the
  form~$\ceu{\Every{e}\,{\stmt}}$ or~$\ceu{\Fin{\stmt}}$ occurs in the
  program, then~$\stmt$ does not contain occurrences of $\ceu{\Loop}$,
  $\ceu{\Break}$, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, $\ceu{\Every}$,
  or~$\ceu{\Fin}$.
\end{enumerate}

Restrictions~\ref{sec.sem.restrictions.1} and~\ref{sec.sem.restrictions.2}
prevent the use of undeclared variables and orphan~$\ceu{\Break}$'s.
Restriction~\ref{sec.sem.restrictions.3} ensures that the program does not
have an infinite loop with a body that runs in zero time (which would
violate the synchronous hypothesis).  And
restriction~\ref{sec.sem.restrictions.4} ensures that the body of
$\ceu{\Every}$ and~$\ceu{\Fin}$ statements always execute to completion
within the same reaction.  Similar restrictions exist in full \CEU, as
discussed in Section~\ref{sec.ceu}.  All restrictions can be easily verified
by inspecting the abstract syntax tree of programs.

From now on, whenever we speak of a basic \CEU program we mean a well-formed
basic \CEU program.

\subsection{From Full \CEU to Basic \CEU}
\label{sec.sem.concrete}

Most statements of full \CEU are also present in basic \CEU.  These statements
in common, however, are not exactly equivalent.  It is sometimes the case
that a statement of full \CEU (say~\code{await}) has more features than its
basic \CEU counterpart ($\ceu{\AwaitInt}$).  In this section, we discuss how
the extra features of full \CEU are implemented in basic \CEU.

\subsubsection*{Await and emit}

The \code{await} and \code{emit} primitives of full \CEU are slightly more
complex than those of basic \CEU, as they support communication of values
between them.

Figure~\ref{lst.await_emit} shows a translation that adds a variable to hold
the value being communicated.
%
The original full \CEU code in Listing~\ref{lst.await_emit.a} declares an
internal event \code{e} (ln~2) and has an \code{await} (ln~4) and an
\code{emit} (ln~10) that communicate the value~$1$ between the trails in
parallel.
%
The translation to basic \CEU in Listing~\ref{lst.await_emit.b} declares an
additional shared variable \code{e\_} (ln~1) to hold the emitted value
(ln~9) and which can be accessed by the awaking trail (ln~5).

External events require a similar translation, i.e., each event needs a
corresponding global variable shared between all awaiting trails.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.a},
]

event int e;
par/or do
  var int v = await e;

  <...>
with
  <...>

  emit e(1);
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.b},
]
var int e_;
event int e;
par/or do
  await e;
  var int v = e_;
  <...>
with
  <...>
  e_ = 1;
  emit e;
end
\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for \code{await} and \code{emit}. }
\label{lst.await_emit}
\end{figure}

\subsubsection*{First-class timers}

To add support for first-class timers to basic \CEU , we introduce a
\code{TIMER} input event, which notifies the passage of time, and two global
variables: \code{timer\_}, which holds the elapsed time, and \code{delta\_},
which holds the residual time (initially set to 0).

Listing~\ref{lst.TIMER.b} shows the basic \CEU program resulting from the
translation of the two timers shown in Listing~\ref{lst.TIMER.a} (ln~1,11).
A timer first adds a (possibly) negative delta from the time it should await
(ln~1).  Then, it enters in a loop that awakes on every occurrence of
\code{TIMER} (ln~7) and decrements the time it should await (ln~8).  Each
iteration of the loop checks if the timer has expired (ln~3), and sets the
new delta, which may affect a timer in sequence.  The check happens before
the await because the timer may already start expired due to the residual
time.

\begin{figure}[!ht]
\begin{minipage}[t]{0.33\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.a},
]
await 10ms;









await 1ms;

\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.63\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.b},
]
var int tot_ = 10000 + delta_;
loop do
    if tot_ <= 0 then
        delta_ = tot_;
        break;
    end
    await TIMER;
    tot_ = tot_ - timer_;
end

var int tot_ = 1000 + delta_;
<...> // same loop as above
\end{lstlisting}
\end{minipage}
\caption{ Full-to-Basic translation for timers. }
\label{lst.TIMER}
\end{figure}

\subsubsection*{Finalization}

% Finally, a ``\code{finalize $A$ with $B$ end; $C$}'' in the concrete
% language is equivalent to ``\ceu{A;\;((\Fin{B})\ \ParOr\ C)}'' in the abstract
% language.  In the concrete language, $A$ and~$C$ execute in sequence, and
% the finalization code~$B$ is implicitly suspended waiting for~$C$
% to terminate.  In the abstract language, ``$\ceu{\Fin B}$'' suspends forever
% when reached (it is an awaiting statement that never awakes).  Hence, we
% need an explicit \code{or} to execute~$C$ in parallel, whose termination
% aborts ``$\ceu{\Fin B}$'', which finally causes~$B$ to execute (by the
% semantic rules below).

The biggest mismatch between full \CEU and basic \CEU is in their support
for finalization, i.e., between the statements \code{finalize} of full \CEU
and $\ceu{\Fin}$ of basic \CEU.
%
Listing~\ref{3.lst.fin.a} shows a full \CEU program containing an explicit
block (ln~1--8) that executes the statements in \code{<A>} (ln~3) immediately
followed by \code{<C>} (ln~7), and unconditionally executes \code{<B>}
(ln~5) when the block terminates or aborts.
%
To simulate this behavior in basic \CEU we need to perform the translation
shown in Listing~\ref{3.lst.fin.b}.  The basic \CEU code also executes
\code{<A>} (ln~1) immediately followed by \code{<C>} (ln~5).  The difference
is that the basic \code{fin <B>} statement (ln~3) blocks the pending statement
forever, which only awakes and executes when it is aborted.  The
\code{par/or} (ln~2--6) serves this purpose since it allows \code{<C>} to
execute immediately and aborts the \code{fin} when terminating.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.a},
]
do
    finalize
        <A>
    with
        <B>
    end
    <C>
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.b},
]
<A>
par/or do
    fin <B>
with
    <C>
end


\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for finalization. }
\label{3.lst.fin}
\end{figure}

\subsection{Operational Semantics}
\label{sec.sem.opsem}

We proceed to formalize the operation of the basic \CEU interpreter.  Our
goal here is twofold.  First, we want to define a function~$\reaction$ that
describes precisely the operation steps taken by the interpreter to compute
a single reaction to an external event.  Second, we want to establish
(prove) some properties of this function.  In particular, we want to
establish that:
\begin{enumerate}
\item $\reaction$ is indeed a function: the same program will always react
  in the same way to a same external event (i.e., reactions are
  deterministic);
\item $\reaction$ is a total function: its computation always yields a
  result (i.e., reactions terminate); and
\item the amount of memory used by $\reaction$ never exceeds a fixed
  threshold which depends solely on the input program (i.e., reactions are
  memory-bounded).
\end{enumerate}

We will define $\reaction$ using a set of rules for a small-step operational
semantics~\cite{Plotkin-G-D-1981}.  These rules dictate how the internal
state of the basic \CEU interpreter progresses while it is computing a
reaction.  A snapshot of this internal state is called a \emph{description},
denoted~$\delta$, and consists of a quadruple~$\<\stmt,\ell,e,\theta>$ where
\begin{itemize}
\item $\stmt$ is a well-formed basic \CEU program;
\item $\ell$ is a nonnegative integer, called the stack level;
\item $e$ is an event identifier or the empty identifier~$\nil$;
  and
\item $\theta$ is a memory.
\end{itemize}

We will detail the precise meaning and purpose of the components of the
description in due course.  For now, the important thing is that the steps
taken by the interpreter to compute a reaction can be viewed as transitions
between descriptions.  The transitions are dictated by rules hard-coded in
the interpreter.  Each rule establishes that when the interpreter is in a
description~$\delta$ and certain criteria are met, then it will
\emph{transition} to a modified description~$\delta'$, in symbols,
\[
  \delta\trans\delta'.
\]
We call the description on the left-hand side of the symbol~$\trans$ the
\emph{input description}, and the one on its right-hand side the
\emph{output description}.

After transitioning to a modified description, the interpreter repeats the
rule-evaluation/transition process, and continues to do so until a final
description is reached.  This final description, called an \emph{irreducible
  description}, embodies the result of the reaction.

A full \emph{reaction} is thus defined as a sequence of the transitions of
the form
\[
  \delta_0\trans\delta_1\trans\cdots\trans\delta_f.
\]
The initial description~$\delta_0=\<\stmt_0,0,e,\theta_0>$ contains the
three inputs of the reaction: the text of the program at the beginning of
the reaction ($\stmt_0$), the event~$e$ to which the program must react, and
the memory~$\theta_0$ holding the values of the variables of~$\stmt_0$.  The
final description~$\delta_f=\<stmt_f,0,\nil,\theta_f>$ contains the two
outputs of the reaction: the text of the program at the end of the reaction
($\stmt_f$) and the memory~$\theta_f$ holding the values of the variables
of~$\stmt_f$.  The output program~$\stmt_f$ and memory~$\theta_f$ are used
by the interpreter as inputs in the next reaction.

We write~$\delta_0\trans[i]\delta_f$ to indicate that $\delta_0$ leads
to~$\delta_f$ after exactly~$i$ transitions, and we
write~$\delta_0\trans[*]\delta_f$ to indicate that it does so after an
unspecified but finite number of transitions.  Using this notation, we can
define function~$\reaction$ (the first part of our goal) as follows:
\[
  \reaction(\stmt_0,\theta_0,e)=\<\stmt_f,\theta_f>
\]
if, and only if,
\[
  \<\stmt_0,0,e,\theta_0>\trans[*]\<\stmt_f,0,\nil,\theta_f>,
\]
where~$\<\stmt_f,0,\nil,\theta_f>$ is an irreducible description.  Under
this definition, $\reaction$ will be deterministic, terminating, and
memory-bounded (the second part of goal) if relation~$\trans[*]$ happens to
be so.  That this is the case is a consequence of the way transitions are
defined, as we will see in Section~\ref{sec.proofs}.

The next two sections, Sections~\ref{sec.sem.outermost}
and~\ref{sec.sem.nested}, give the rules for transitions.  There are two
types of transitions: \emph{outermost transitions} $\out$ and \emph{nested
  transitions} $\nst$.  The rules for~$\out$ and~$\nst$ transitions are
listed all at once in Figure~\ref{fig.rules} (page~\pageref{fig.rules}).
Each of these rules has the form
\[
  \AxiomC{\strut condition$_1$}
  \AxiomC{\strut condition$_2$}
  \AxiomC{$\cdots$}
  \AxiomC{\strut condition$_n$}
  \QuaternaryInfC{$\delta\trans\delta'$}
  \DisplayProof
\]
and establishes that a transition~$\delta\trans\delta'$ shall take place if
condition$_1$, condition$_2$, \dots, and condition$_n$ are all true.  If the
number of conditions is zero, then the line is omitted and the rule is
called an axiom.

\subsection{Outermost Transitions}
\label{sec.sem.outermost}

The rules \R{push} and \R{pop} for~$\out$ transitions (see
Figure~\ref{fig.rules}) are non-recursive definitions that apply to the
program as a whole.  These are the only rules that manipulate the stack
level---the component of descriptions that determines the order of execution
of nested reactions.

% \begin{gather*}
%   \AxiomC{$e\ne\nil$}
%   \UnaryInfC{$\<\stmt,n,e,\theta>\out\<\bcast(\stmt,e),n+1,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{push}\\
%   %%
%   \AxiomC{$n>0$}
%   \AxiomC{$\stmt=\ceu{\Nop}\lor\isblk(\stmt,n)$}
%   \BinaryInfC{$\<\stmt,n,\nil,\theta>\out\<\stmt,n-1,\nil,\theta>$}
%   \Rtag{pop}
%   \DisplayProof
% \end{gather*}

Rule \R{push} matches whenever there is a nonempty event in the input
description; it instantly broadcasts the event to the program, which means
it:
\begin{enumerate*}[label=(\roman*)]
\item uses function~$\bcast$ (defined below) to awake active
  $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, and $\ceu{\Every}$ statements;
\item creates a nested reaction by increasing the stack level ($\ell$
  becomes~$\ell+1$); and
\item consumes the input event ($e$ becomes~$\nil$).
\end{enumerate*}

Function~$\bcast$ is defined as
\begin{align*}
  \bcast(\ceu{\AwaitExt(e)},e)
  &=\ceu{\Nop}\\
  %%
  \bcast(\ceu{\AwaitInt(e)},e)
  &=\ceu{\Nop}\\
  %%
  \bcast(\ceu{\Every{e\,\stmt}},e)
  &=\ceu{\stmt;\Every{e\,\stmt}}\\
  %%
  \bcast(\ceu{\stmt_1;\stmt_2},e)
  &=\ceu{\bcast(\stmt_1,e);\stmt_2}\\
  %%
  \bcast(\ceu{\AtVar{v\,n\,\stmt}})
  &=\ceu{\AtVar{v\,n\,\bcast(\stmt,e)}}\\
  %%
  \bcast(\ceu{\stmt_1\AtLoop{\stmt_2}},e)
  &=\ceu{\bcast(\stmt_1,e)\AtLoop{\stmt_2}}\\
  %%
  \bcast(\ceu{\stmt_1\AtParAnd{\stmt_2}},e)
  &=\\
  &\hskip-3em\ceu{{\bcast(\stmt_1,e)}\AtParAnd{\bcast(\stmt_2,e)}}\\
  %%
  \bcast(\ceu{\stmt_1\AtParOr{\stmt_2}},e)
  &=\\
  &\hskip-3em\ceu{{\bcast(\stmt_1,e)}\AtParOr{\bcast(\stmt_2,e)}}\\
  %%
  bcast(\_,e)&=\_\quad\text{\emph{(otherwise)}}
\end{align*}
%%
where the underscore ($\_$) denotes the omitted patterns.

Function $\bcast$ takes a statement~$\stmt$ and an event~$e$ and awakes any
trails in~$\stmt$ awaiting for~$e$.  It does so by converting any active
$\ceu{\protect\AwaitExt(e)}$ and $\ceu{\protect\AwaitInt(e)}$ statements
in~$\stmt$ to~$\ceu{\protect\Nop}$ (and thus consuming them) and by
unwinding once any active $\ceu{\protect\Every{e\,\stmt'}}$ statements
in~$\stmt$ (and thus allowing their body~$\stmt'$ to execute once).

Note that \R{push} is the only rule that uses function~$\bcast$.  Moreover,
it is the only rule in the semantics that matches a nonempty event
($e\ne\nil$) in the input description.

Rule \R{pop}, the other $\out$ rule, simply decreases the stack level by
one.  Rule~\R{pop} can be applied whenever the stack level is greater than
zero ($\ell>0$) and the program is blocked or terminated
($\stmt=\ceu{\Nop}$).  As we will see, these conditions ensure that an
$\ceu{\EmitInt}$ only resumes after its nested reaction completes and blocks
at the current stack level.

In order to determine whether the program is blocked, \R{pop} uses
predicate~$\isblk$.  This predicate evaluates to~\emph{true} if all parallel
trails in the given program are blocked waiting for events, finalization
clauses, or certain stack levels; otherwise, it evaluates to \emph{false}.
Predicate~$\isblk$ is defined as
%%
\begin{align*}
  \isblk(\ceu{\AwaitExt(e)},\ell)
  &=\mathit{true}\\
  %%
  \isblk(\ceu{\AwaitInt(e)},\ell)
  &=\mathit{true}\\
  %%
  \isblk(\ceu{\Every{e\,\stmt}},\ell)
  &=\mathit{true}\\
  %%
  \isblk(\ceu{\RunAt(\ell')},\ell)
  &=(\ell>\ell')\\
  %%
  \isblk(\ceu{\Fin{\stmt}},\ell)
  &=\mathit{true}\\
  %%
  \isblk(\ceu{\stmt_1;\stmt_2},\ell)
  &=\isblk(\stmt_1,\ell)\\
  %%
  \isblk(\ceu{\AtVar{v\,\ell\,\stmt}},\ell)
  &=\isblk(\stmt,\ell)\\
  %%
  \isblk(\ceu{\stmt_1\AtLoop{\stmt_2}},\ell)
  &=\isblk(\stmt_1,\ell)\\
  %%
  \isblk(\ceu{\stmt_1\AtParAnd{\stmt_2}},\ell)
  &=\\
  &\hskip-3em\isblk(\stmt_1,\ell)\land\isblk(\stmt_2,\ell)\\
  %%
  \isblk(\ceu{\stmt_1\AtParOr{\stmt_2}},\ell)
  &=\\
  &\hskip-3em\isblk(\stmt_1,\ell)\land\isblk(\stmt_2,\ell)\\
  %%
  \isblk(\_,\ell)
  &=\mathit{false}\quad\text{\emph{(otherwise)}}
\end{align*}
%%
where the underscore ($\_$) denotes the omitted patterns.

Besides \R{pop}, predicate $\isblk$ is also used as a condition in the
$\nst$ rules for advancing the right-hand side of parallel compositions
(which can only advance if the left-hand side is blocked).  We detail these
and the other~$\nst$ rules next.

% At the beginning of a reaction, an external event is emitted, which
% triggers rule \R{push}, immediately raising the stack level to~1.  At the
% end of the reaction, the program will block or terminate and successive
% applications of rule~\R{pop} will lead to an irreducible description with
% this same program at stack level~0.

\input{rules}

\subsection{Nested Transitions}
\label{sec.sem.nested}

The~$\nst$ transitions have the general form
\[
\<\stmt,\ell,\nil,\theta>\nst\<\stmt',\ell,e,\theta'>.
\]
They do not affect the stack level and never have an emitted event as a
precondition.  The distinction between~$\out$ and~$\nst$ prevents rules
\R{push} and \R{pop} from matching and, consequently, from inadvertently
modifying the stack level before a nested reaction is over.

A full reaction follows the pattern
%%
\begin{align*}
  \<\stmt_0,0,e_\ext,\theta_0>\outpush
  {\Big[{\nst[*]}{\out}\Big]{*}}
  \null\mathbin{\nst[*]\outpop}\<\stmt_f,0,\nil,\theta_f>.
\end{align*}
%%
First, a~$\outpush$ starts a nested reaction at level~1.  Then, a series of
alternations between zero or more~$\nst$ transitions and a single~$\out$
transition (stack operation) takes place.  Finally, zero or more $\nst$
transitions followed by a last~$\outpop$ transition, which decrements the
stack level to~0, terminates the reaction.

We now describe the rules for nested transitions (listed in
Figure~\ref{fig.rules}).  Since the $\nst$ rules do not affect the stack
level, whenever convenient, we omit the ``$\ell$'' when discussing them.
Thus, in Figure~\ref{fig.rules}, we sometimes write descriptions as
triples~$\<\stmt,e,\theta>$ with the tacit understanding that there is a
hidden integer~$\ell$ for the stack level between the components~$\stmt$
and~$e$.

\subsubsection*{Emissions}

% \begin{gather*}
%   \<\ceu{\EmitInt(e)},n,\nil,\theta>
%   \nst\<\ceu{\RunAt(n)},n,e,\theta>\Rtag{emit-int}\\
%   %%
%   \<\ceu{\RunAt(n)},n,\nil,\theta>
%   \nst\<\ceu{\Nop},n,\nil,\theta>\Rtag{run-at}
% \end{gather*}

An $\ceu{\EmitInt(e)}$ generates event~$e$ and becomes a
$\ceu{\RunAt(\ell)}$ statement (rule \R{emit-int}); this
$\ceu{\RunAt(\ell)}$ statement only resumes at stack level~$\ell$ (rule
\R{run-at}).

Since every~$\nst$ rule expects the input event to be empty, an application
of \R{emit-int} leads immediately to an application of \R{push} at the outer
level, creating a new level~$\ell+1$ on the stack.  With this new stack
level, the $\ceu{\RunAt}(\ell)$ resulting from the $\ceu{\EmitInt(e)}$ can
only transition after future applications of~\R{pop} put the stack level
back in~$\ell$.

The interplay between \R{emit-int}, \R{push}, \R{pop}, and \R{run-at}
provides the desired stack-based semantics for internal events.

\subsubsection*{Variable declarations and assignments}

There are five $\nst$ rules for dealing with variables: \R{var-expd},
\R{var-nop}, \R{var-brk}, \R{var-adv}, and~\R{assign}.  The last two,
\R{var-adv} and~\R{assign}, are the only rules in the semantics that modify
the memory---the fourth component of descriptions.

A \emph{memory}~$\theta$ is a stack of bindings~$[b_1,\ldots,b_k]$ where
each binding~$b_i$ is a pair~$(v,n)$ associating the variable~$v$ to the
integer value~$n$.  For instance, the memory
\[
  [(v_1,1),(v_2,\bot),(v_1,0)]
\]
has three bindings: $b_1=(v_1,1)$, which is the top-of-stack,
$b_2=(v_2,\bot)$, and~$b_3=(v_1,0)$.  From this memory, we can tell that, at
some point, variable~$v_1$ was declared and set to~$0$.  Later, in the scope
of~$v_1$, variable~$v_2$ was declared but not initialized, hence its
value~$\bot$ (undefined), and in the scope of~$v_2$, variable~$v_1$ was
re-declared (shadowing the initial declaration) and set to~$1$.

The basic \CEU interpreter starts with the empty memory~$\theta=[]$.  When
it encounters a declaration $\ceu{\Var{v\,\stmt}}$, the interpreter
immediately expands it to~$\ceu{\AtVar{v\,\bot\,\stmt}}$ (rule~\R{var-expd})
and proceeds to advance its body~($\stmt$).  At this point, three things can
happen:
\begin{enumerate}
\item If~$\stmt$ is terminated ($=\ceu{\Nop}$), the interpreter consumes the
  whole~$\ceu{\AtVar}$ statement by transforming it into a~$\ceu{\Nop}$
  (rule~\R{var-nop}).
\item If~$\stmt$ is a break~($=\ceu{\Break}$), the interpreter propagates
  the break outwards by transforming the whole~$\ceu{\AtVar}$ statement into
  a~$\ceu{\Break}$ (rule~\R{var-brk}).
\item Otherwise, the interpreter advances~$\stmt$ recursively
  (rule~\R{var-adv}) and updates the~$\ceu{\AtVar}$ statement with the
  resulting body~$\stmt'$, event~$e$, memory~$\theta'$, and
  binding~$(v,n')$.
\end{enumerate}

In rule~\R{var-adv}, the recursive execution of the body ($\stmt$) of
the~$\ceu{\AtVar}$ statement happens in a memory $(v,n):\theta$, i.e., the
memory resulting from pushing binding~$(v,n)$ to the current
memory~$\theta$, which effectively declares~$v$ with value~$n$ in the scope
of~$\stmt$.  Initially, $n=\bot$ (undefined), but any assignments in~$\stmt$
may change that.  Thus, after~$\stmt$ is advanced, the value~$n'$ associated
with variable~$v$ in the (possibly) updated binding~$(v,n')$ is stored back
in the enclosing $\ceu{\AtVar}$ statement.  (The updated binding itself is
popped from the resulting memory because at this point the $\ceu{\AtVar}$
statement is no longer in effect.)

We borrowed the technique used in rule~\R{var-adv} to implement lexical
scoping from the operational semantics of Esterel~\cite{Berry-G-1992}.  Our
version is simpler though.  While in Esterel the memories resulting from
advancing parallel trails need to be merged into a single memory, in \CEU
this is not necessary: parallel trails are always advanced from left to
right and can thus safely operate over the same memory.

The last $\nst$ rule for dealing with variables is~\R{assign}.
Rule~\R{assign} transforms~$\ceu{v\coloneqq\expr}$ into $\ceu{\Nop}$ and
performs the assignment.  That is, it evaluates~$\expr$ to an integer~$n$
and updates the most recent binding of variable~$v$ to~$n$.

Expression evaluation is carried out by function~$\eval$.  For
simplicity, we assume that~$\eval$ always returns an integer.  In
practice, any error in the evaluation, such as access to an uninitialized
variable or division by zero, will cause the interpreter to abort.

Memory updates are carried out by function~$\updt$, which simply updates
the most recent binding of the given variable to the given value:
\[
  \updt((v,n):\theta,v',n')=
  \begin{cases}
    (v,n'):\theta             &\text{if~$v=v'$}\\
    (v,n):\updt(\theta,v',n') &\text{otherwise}.
  \end{cases}
\]
The first syntactic restriction listed in
Section~\ref{sec.sem.restrictions} ensures that~$\updt$ is always defined.

\subsubsection*{Conditionals}

% \begin{gather*}
%   \AxiomC{$\eval(\theta,\expr)\ne0$}
%   \UnaryInfC{$\<\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}},\nil,\theta>
%     \nst\<\stmt_1,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{if-true}\\
%   %%
%   \AxiomC{$\eval(\theta,\expr)=0$}
%   \UnaryInfC{$\<\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}},\nil,\theta>
%     \nst\<\stmt_2,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{if-false}
% \end{gather*}

Rules \R{if-true} and \R{if-false} transform a conditional statement into
its if-part ($\stmt_1$) or else-part ($\stmt_2$) depending on the value to
which the associated expression ($\expr$) evaluates in the current memory.
If it evaluates to a nonzero value, then \R{if-true} applies and the
conditional becomes~$\stmt_1$; otherwise, \R{if-false} applies and the
conditional becomes~$\stmt_2$.

These are the only rules that use the contents of the memory in a way that
affects the control flow.

\subsubsection*{Sequences}

% \begin{gather*}
%   \<\ceu{\Nop;\stmt_2},\nil,\theta>
%   \nst\<\stmt_2,\nil,\theta>
%   \Rtag{seq-nop}\\
%   %%
%   \<\ceu{\Break;\stmt_2},\nil,\theta>
%   \nst\<\ceu{\Break},\nil,\theta>\Rtag{seq-brk}\\
%   %%
%   \AxiomC{$\<\stmt_1,\nil,\theta>\nst\<\stmt_1',e,\theta'>$}
%   \UnaryInfC{$\<\ceu{\stmt_1;\stmt_2},\nil,\theta>
%     \nst\<\ceu{\stmt_1';\stmt_2},e,\theta'>$}
%   \DisplayProof
%   \Rtag{seq-adv}
% \end{gather*}

A sequence whose first part is terminated ($\ceu{\Nop}$) becomes its second
part (rule \R{seq-nop}).  A sequence whose first part is a~$\ceu{\Break}$,
propagates the~$\ceu{\Break}$ outwards by dropping its second part (rule
\R{seq-brk}).  And a sequence whose first part is neither $\ceu{\Nop}$
nor~$\ceu{\Break}$ advances to the sequence, event, and memory resulting
from advancing just its first part (rule \R{seq-adv}).

\subsubsection*{Loops}

% \begin{gather*}
%   \<\ceu{\Loop{\stmt}},\nil,\theta>
%   \nst\<\ceu{(\stmt\AtLoop{\stmt});
%     \Restore({\left|\theta\right|})},\nil,\theta>
%   \Rtag{loop-expd}\\
%   %%
%   \<\ceu{\Nop\AtLoop{\stmt_2}},\nil,\theta>
%   \nst\<\ceu{\Loop{\stmt_2}},\nil,\theta>
%   \Rtag{loop-nop}\\
%   %%
%   \<\ceu{\Break\AtLoop{\stmt_2}},\nil,\theta>
%   \nst\<\ceu{\Nop},\nil,\theta>
%   \Rtag{loop-brk}\\
%   %%
%   \AxiomC{$\<\stmt_1,\nil,\theta>\nst\<\stmt_1',e,\theta'>$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtLoop{\stmt_2}},\nil,\theta>
%     \nst\<\ceu{\stmt_1'\AtLoop{\stmt_2}},e,\theta'>$}
%   \DisplayProof
%   \Rtag{loop-adv}
% \end{gather*}

When the interpreter encounters a $\ceu{\Loop\stmt}$, it unwinds it once,
expanding it to~$\ceu{\stmt\AtLoop{\stmt}}$ (rule \R{loop-expd}).

The remaining rules for loops are similar to those for sequences but use
``\texttt{@}'' as separators to bind the current code of the loop to its
next iteration.  Rules \R{loop-nop} and \R{loop-adv} are analogous to rules
\R{seq-nop} and \R{seq-adv}.  They advance the current code of the loop
until it becomes a~$\ceu{\Nop}$.  When this happens the loop is restarted
(\R{loop-nop}).  (Note that if we had used ``\texttt{;}'' as a separator in
loops, rules \R{loop-brk} and \R{seq-brk} would conflict.)  Finally, rule
\R{loop-brk} escapes the enclosing loop, transforming everything into
a~$\ceu{\Nop}$.

\subsubsection*{Par/and and par/or compositions}

% \begin{gather*}
%   \begin{split}
%     &\<\ceu{\stmt_1\ParAnd{\stmt_2}},n,\nil,\theta>\\
%     &\qquad\null\nst\<\ceu{\stmt_1\AtParAnd(\RunAt(n);\stmt_2)},
%      n,\nil,\theta>
%   \end{split}
%   \Rtag{par/and-expd}\\
%   %%
%   \begin{split}
%     &\<\ceu{\stmt_1\ParOr{\stmt_2}},n,\nil,\theta>\\
%     &\qquad\null\nst\<\ceu{(\stmt_1\AtParOr(\RunAt(n);\stmt_2));
%       \Restore(\left|\theta\right|)},n,\nil,\theta>
%   \end{split}
%   \Rtag{par/or-expd}
% \end{gather*}

When the interpreter encounters $\ceu{\ParAnd}$ and $\ceu{\ParOr}$, it
expands them to $\ceu{\AtParAnd}$ and~$\ceu{\AtParOr}$ prefixing a
$\ceu{\RunAt(\ell)}$ to the right-hand side of the resulting compositions
(rules \R{par/and-expd} and \R{par/or-expd}).  The $\ceu{\RunAt(\ell)}$
ensures that any reachable~$\ceu{\EmitInt}$ on the left-hand side executes
to completion before the right-hand side starts.

There are twelve rules for advancing the sides of~$\ceu{\AtParAnd}$
and~$\ceu{\AtParOr}$ statements.  Each of these rules ensures that the
left-hand side always advances before the right-hand side.  That is, in each
rule the right-hand side is advanced only when the left-hand side is
blocked.  The twelve rules are divided into three groups:
\begin{enumerate*}[label=(\roman*)]
\item those that apply when one of the sides is $\ceu{\Nop}$;
\item those that apply when one of the sides is $\ceu{\Break}$; and
\item those that apply when neither side is $\ceu{\Nop}$ or $\ceu{\Break}$.
\end{enumerate*}

We begin by presenting the rules of the last group, which do not involve the
termination of one of the sides.
%%
% \begin{gather*}
%   \AxiomC{$\<\stmt_1,n,\nil,\theta>\nst\<\stmt_1',n,e,\theta'>$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParAnd{\stmt_2}},n,\nil,\theta>
%     \nst\<\ceu{\stmt_1'\AtParAnd{\stmt_2}},n,e,\theta'>$}
%   \DisplayProof
%   \Rtag{par/and-adv1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \AxiomC{$\<\stmt_2,n,\nil,\theta'>\nst\<\stmt_2',n,e,\theta'>$}
%   \BinaryInfC{$\<\ceu{\stmt_1\AtParAnd{\stmt_2}},n,\nil,\theta>
%     \nst\<\ceu{\stmt_1\AtParAnd{\stmt_2'}},n,e,\theta'>$}
%   \DisplayProof
%   \Rtag{par/and-adv2}\\
%   %%
%   \AxiomC{$\<\stmt_1,n,\nil,\theta>\nst\<\stmt_1',n,e,\theta'>$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParOr{\stmt_2}},n,\nil,\theta>
%     \nst\<\ceu{\stmt_1'\AtParOr{\stmt_2}},n,e,\theta'>$}
%   \DisplayProof
%   \Rtag{par/or-adv1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \AxiomC{$\<\stmt_2,n,\nil,\theta>\nst\<\stmt_2',n,e,\theta'>$}
%   \BinaryInfC{$\<\ceu{\stmt_1\AtParOr{\stmt_2}},n,\nil,\theta>
%     \nst\<\ceu{\stmt_1\AtParOr{\stmt_2'}},n,e,\theta'>$}
%   \DisplayProof
%   \Rtag{par/or-adv2}
% \end{gather*}

Rules~\R{par/and-adv1} and \R{par/or-adv1} match whenever the left-hand side
of the composition is not blocked (see $\isblk$ in
Section~\ref{sec.sem.outermost}).  They advance the composition the to the
statement, event, and memory resulting from advancing just its left-hand
side.  Rules~\R{par/and-adv2} and \R{par/or-adv2} are similar, but they act
on the right-hand side and match only when the left-hand side is blocked.

The next rules apply whenever one of the sides of the $\ceu{\AtParAnd}$ or
$\ceu{\AtParOr}$ terminates (becomes a $\ceu{\Nop}$).
%%
% \begin{gather*}
%   \<\ceu{{\Nop}\AtParAnd{\stmt_2}},n,\nil,\theta>
%   \nst\<\stmt_2,n,\nil,\theta>
%   \Rtag{par/and-nop1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParAnd{\Nop}},n,\nil,\theta>
%     \nst\<\stmt_1,n,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{par/and-nop2}\\
%   %%
%   \<\ceu{{\Nop}\AtParOr{\stmt_2}},n,\nil,\theta>
%   \nst\<\clear(\stmt_2),n,\nil,\theta>
%   \Rtag{par/or-nop1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParOr{\Nop}},n,\nil,\theta>
%     \nst\<\clear(\stmt_1),n,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{par/or-nop2}
% \end{gather*}

In a~$\ceu{\AtParAnd}$, if one of the sides terminates, the composition
becomes the other side (rules \R{par/and-nop1} and \R{par/and-nop2}).  In
a~$\ceu{\AtParOr}$, however, if one of the sides terminates, the whole
composition terminates and function $\clear$ is called to finalize the
aborted side (rules \R{par/or-nop1} and \R{par/or-nop2}).

Function~$\clear$ takes a statement~$\stmt$ and extracts the bodies of all
active $\ceu{\protect\Fin}$ statements in~$\stmt$, returning them in a
sequence:
%%
\begin{align*}
  \clear(\ceu{\AwaitExt(e)})
  &=\ceu{\Nop}\\
  %%
  \clear(\ceu{\AwaitInt(e)})
  &=\ceu{\Nop}\\
  %%
  \clear(\ceu{\Every{e\,\stmt}})
  &=\ceu{\Nop}\\
  %%
  \clear(\ceu{\RunAt(\ell)})
  &=\ceu{\Nop}\\
  %%
  \clear(\ceu{\Fin{\stmt}})
  &=\stmt\\
  %%
  \clear(\ceu{\stmt_1;\stmt_2})
  &=\clear(\stmt_1)\\
  %%
  \clear(\ceu{\AtVar{v\,n\,\stmt}})
  &=\clear(\stmt)\\
  %%
  \clear(\ceu{\stmt_1\AtLoop{\stmt_2}})
  &=\clear(\stmt_1)\\
  %%
  \clear(\ceu{\stmt_1\AtParAnd{\stmt_2}})
  &=\ceu{\clear(\stmt_1);\clear(\stmt_2)}\\
  %%
  \clear(\ceu{\stmt_1\AtParOr{\stmt_2}})
  &=\ceu{\clear(\stmt_1);\clear(\stmt_2)}\\
  %%
  \clear(\_)
  &=\bot\quad\text{\emph{(undefined)}}
\end{align*}

When applied to the aborted side of a~$\ceu{\AtParOr}$, $\clear$ returns all
finalization code associated with it (if any).  Thus, by expanding to a
$clear$ call on the aborted side, rules \R{par/or-nop1} and \R{par/or-nop2},
ensure that the composition is properly finalized.

Note that as there are no transition rules for~$\ceu{\Fin}$ statements, once
reached, a $\ceu{\Fin}$ halts and will only be consumed if its trail is
aborted.  At this moment, its body will execute as a result of the~$\clear$
call.  Note also that the syntactic restrictions of
Section~\ref{sec.sem.restrictions} ensure that the body of a~$\ceu{\Fin}$
statement always execute within the same reaction.

Finally, a~$\ceu{\Break}$ in one of the sides of a $\ceu{\AtParAnd}$ or
$\ceu{\AtParOr}$ is propagated outwards, terminating the composition and
properly finalizing the aborted side with a~$\clear$ call
(rules~\R{par/and-brk1}, \R{par/and-brk2}, \R{par/or-brk1},
and~\R{par/or-brk2}).
%%
% \begin{gather*}
%   \<\ceu{{\Break}\AtParAnd{\stmt_2}},n,\nil,\theta>
%   \nst\<\ceu{\clear(\stmt_2);\Break},n,\nil,\theta>
%   \Rtag{and-brk1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParAnd{\Break}},n,\nil,\theta>
%     \nst\<\ceu{\clear(\stmt_1);\Break},n,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{and-brk2}\\[\baselineskip]
%   %%
%   \<\ceu{{\Break}\AtParOr{\stmt_2}},n,\nil,\theta>
%   \nst\<\ceu{\clear(\stmt_2);\Break},n,\nil,\theta>
%   \Rtag{or-brk1}\\
%   %%
%   \AxiomC{$\isblk(\stmt_1,n)$}
%   \UnaryInfC{$\<\ceu{\stmt_1\AtParOr{\Break}},n,\nil,\theta>
%     \nst\<\ceu{\clear(\stmt_1);\Break},n,\nil,\theta>$}
%   \DisplayProof
%   \Rtag{or-brk2}
% \end{gather*}

\subsection{Using the Rules to Compute Reactions}

We conclude the discussion of the rules for~$\out$ and~$\nst$ transitions
with an example of their application in the computation of reactions.

\begingroup
\newcommand*{\led}{\mathit{led}}
\newcommand*\evtboot{e_{0}}
\newcommand*\evtbttn{e_{\mathit{bt}}}
\newcommand*\evtrecv{e_{\mathit{rd}}}
\newcommand*\ddd{\mathmakebox[1em][c]{.\hfil.\hfil.}}

Consider the following basic \CEU program:
\begin{align*}
  &\ceu{\Var{\,\led}}\\
  &\quad\ceu{\big(\AwaitExt(\evtbttn)\big)\enspace\ParOr\enspace}
  \begin{aligned}[t]
    \big(&\ceu{\Loop}\enspace
    \begin{aligned}[t]
      \big(&\ceu{\led\coloneqq1;\AwaitExt(\evtrecv)};\\
       &\ceu{\led\coloneqq0;\AwaitExt(\evtrecv)}\big);\\
    \end{aligned}\\
    &\ceu{\Fin\,{\led\coloneqq0}}\big)
  \end{aligned}
\end{align*}
This is a simplified basic \CEU version of the full \CEU program presented
in Listing~\ref{lst.ceu} (page~\ref{lst.ceu}).  As its full \CEU
counterpart, this program toggles a LED whenever a radio packet
(event~$\evtrecv$) is received, terminating on a button press
(event~$\evtbttn$) always with the LED off---the state of the led is
represented by variable~$\led$.

We will compute three reactions of the above program.  First, to the
bootstrap event~$\evtboot$ (the bootstrap reaction) and then to the external
events~$\evtrecv$ and~$\evtbttn$ (in this order).  We will execute the
reactions in series, which means that the outputs of a reaction will become
inputs of the next reaction.

The bootstrap reaction starts with a description
\[
  \<\ceu{\Var{\led}\,\ddd}\,,0,\evtboot,[]>,
\]
where~$\ceu{\Var{\led}\,\ddd}$ is the original program, $\evtboot$ is the
bootstrap event, and~$[]$ is the empty memory, and proceeds as
follows:\footnote{The arrow ($\to$) denotes an~$\out$ or~$\nst$ transition
  and the hook ($\hookrightarrow$) introduces a recursive $\nst$ transition.
  We only show the affected part of statements, and any updates on the
  level~$\ell$, event~$e$, or memory~$\theta$ appear on the right-hand
  side.}

\makeatletter
\newsavebox{\trarrow}
\savebox{\trarrow}{$\xrightarrow{\phantom{xxxx}}$}
\newcommand*\@tr[2]{%
  \rlap{\usebox{\trarrow}}%
  \rlap{\raisebox{1.05\height}%
    {\makebox[\wd\trarrow][c]{\scriptsize{\strut#1}}}}%
  \raisebox{-.7\height}%
  {\makebox[\wd\trarrow][c]{\scriptsize{\strut#2}}}%
}
\newcommand*\TR[4]{\hspace*{#1em}$\mathop{\@tr{#2}{#3}}\ceu{#4}$}
\newcommand*\HK[2]{\hspace*{#1em}$\xhookrightarrow{\hphantom{xxxx}}\ceu{#2}$}
\makeatother

\begin{center}
\begin{tabularx}{\columnwidth}{X}
  \TR{0}{push}{}
  {\Var{\led}\,\ddd}
  \hfill$\ell=1,e=\nil,\theta=[]$\\
  %%
  \TR{0}{var}{expd}
  {\AtVar{\led\,\bot}\,\ddd\ParOr\ddd}\\
  %%
  \HK{1}
  {\ddd\ParOr\ddd}
  \hfill$\theta=[(\led,\bot)]$\\
  %%
  \TR{1}{par/or}{expd}
  {\AwaitExt(\evtbttn)\AtParOr(\Loop\ddd)}\\
  %%
  \HK{2}
  {\Loop\ddd}\\
  %%
  \TR{2}{loop}{expd}
  {\led\coloneqq1;\ddd\AtLoop\ddd}\\
  %%
  \HK{3}
  {\led\coloneqq1;\AwaitExt(\evtrecv);\ddd}\\
  %%
  \HK{4}
  {\led\coloneqq1}\\
  %%
  \TR{4}{assign}{}
  {\Nop}
  \hfill$\theta=[(\led,1)]$\\
  %%
  \TR{3}{seq}{nop}
  {\AwaitExt(\evtrecv);\ddd}\\
  %%
  \TR{2}{loop}{adv}
  {\AwaitExt(\evtrecv);\ddd\AtLoop\ddd}\\
  %%
  \TR{1}{par/or}{adv2}
  {\AwaitExt(\evtbttn)\AtParOr(\AwaitExt(\evtrecv);\ddd\AtLoop\ddd)}\\
  %%
  \TR{0}{var}{adv}
  {\AtVar{\led\,1}\,\ddd\AtParOr\ddd}
  \hfill$\theta=[]$
  %%
  \TR{0}{pop}{}
  {\AtVar{\led\,1}\,\ddd\AtParOr\ddd}
  \hfill$\ell=0$
\end{tabularx}
\end{center}

So, the bootstrap reaction terminates with variable~$\led$ set to~$1$ and
with both sides of the $\ceu{\AtParOr}$ blocked on~$\ceu{\AwaitExt}$
statements: the left-hand side waiting on~$\evtbttn$ and the right hand-side
waiting on~$\evtrecv$.

This is a general property of reactions.  Every reaction eventually blocks
in~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, $\ceu{\Every}$, $\ceu{\Fin}$,
or~$\ceu{\RunAt}$ statements in parallel trails.  If none of these trails is
blocked in a~$\ceu{\RunAt}$, then the program can no longer advance and the
reaction is terminated.

The second reaction is a reaction to event~$\evtrecv$.  It starts with the
description produced by the previous reaction but with~$\nil$ replaced
by~$\evtrecv$, i.e.,
\begin{align*}
  \langle&\ceu{\AtVar{\led\,1}\,\AwaitExt(\evtbttn)}\\
         &\ceu{\AtParOr(\AwaitExt(\evtrecv);\led\coloneqq0;\ddd\AtLoop\ddd)},
           0,\evtrecv,[]\rangle
\end{align*}
and after three transitions in the outer level (\R{push}, \R{var-adv}, and
\R{pop}) results in:
\begin{align*}
  \langle&\ceu{\AtVar{\led\,0}\,\AwaitExt(\evtbttn)}\\
         &\ceu{\AtParOr(\AwaitExt(\evtrecv);\led\coloneqq1;\ddd\AtLoop\ddd)},
           0,\nil,[]\rangle
\end{align*}
where~$\led$ is set to~$0$ and the event is consumed.

The third and last reaction is a reaction to event~$\evtbttn$.  It starts
with the description produced in the previous reaction (with~$\evtbttn$
replaced for~$\nil$) and proceeds as follows:
\begin{center}
\begin{tabularx}{\columnwidth}{X}
  \TR{0}{push}{}
  {\AtVar{\led\,0}\,\Nop\AtParOr\ddd}
  \hfill$\ell=1,e=\nil,\theta=[]$\\
  %%
  \HK{1}
  {\Nop\AtParOr\ddd}
  \hfill$\theta=[(\led,0)]$\\
  %%
  \TR{1}{par/or}{nop1}
  {\led\coloneqq0}
  \hfill$(=\clear(\ddd))$\\
  %%
  \TR{1}{assign}{}
  {\Nop}
  \hfill$\theta=[(\led,0)]$\\
  %%
  \TR{0}{var}{adv}
  {\AtVar{\led\,0}\,\Nop}
  \hfill$\theta=[]$\\
  %%
  \TR{0}{var}{nop}
  {\Nop}\\
  %%
  \TR{0}{pop}{}
  {\Nop}
  \hfill$\ell=0$
\end{tabularx}
\end{center}

After the third reaction the program is terminated (consists of a single
$\ceu{\Nop}$) and no longer responds to the environment.

\endgroup

% LocalWords:  ln AST stmt expd nop brk bt xxxx

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "index.tex"
%%% End:
