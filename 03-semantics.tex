\section{Formal Semantics of \CEU}
\label{sec.sem}

We now introduce and formalize the semantics of a reduced version of \CEU,
called \emph{basic \CEU}.  Although simpler than the full language presented
in Section~\ref{sec.ceu}, basic \CEU is expressive enough to capture all the
essential characteristics of full \CEU, in particular, the stack-based
execution of internal events.  Once basic \CEU is defined, the more
elaborate constructs of full \CEU can be defined on top of it, as we will
discuss shortly.

The statements of basic \CEU are presented in Figure~\ref{fig.sem.syntax}.
In the figure, the metavariables~$v$ (ln~2), $e$ (ln~3--5, 10), and~$n$
(ln~15--16) range over variable identifiers, event identifiers, and
integers.  The metavariable~$\vars$ (ln~1) denotes zero or more variable
identifiers.  The metavariable~$\stmt$ (ln~1, 7--13, 17--19) denotes a
statement, i.e., any of the statements of
Figure~\ref{fig.sem.syntax}---complex statements are defined recursively in
terms of simpler statements.  Finally, the metavariable $\expr$ (ln~2, 7)
denotes an expression.

\gl{Outra opção para o basic seria usar o mesmo estilo do full mas colocar
  um $\upbeta$ no final.  E.g.,
  \lstinline[mathescape=true,keywords={block}]|block$_\upbeta$ ...|,
  \lstinline[mathescape=true,keywords={set}]|set$_\upbeta$ x:=y|,
  \lstinline[mathescape=true,keywords={seq}]|seq$_\upbeta$ x; y|,
  \lstinline[mathescape=true]|if$_\upbeta$...then...else...|,
  \lstinline[mathescape=true]|...par/and$_\upbeta$...|.  Assim daria para
  usar $\CEU_\upbeta$ (basic) e \CEU (full).}

\gl{Que tal ``local'' ao invés de ``block''?  Já que ``block'' também
  significa bloquear.}

\begin{figure}[ht!]
\begingroup
\setlength{\jot}{0pt}
\def\N#1{\mathllap{\text{\scriptsize{#1}}\hspace{1em}}}
\begin{empheq}[box=\fbox]{alignat*=3}
     \N1&\hskip4pt&&\ceu{\Block{\vars\ \stmt}}
                                    &\quad&\text{\it declaration block}\\
     \N2&&&\ceu{v\coloneqq\expr}         &&\text{\it assignment statement}\\
     \N3&&&\ceu{\AwaitExt(e)}            &&\text{\it await external event}\\
     \N4&&&\ceu{\AwaitInt(e)}            &&\text{\it await internal event}\\
     \N5&&&\ceu{\EmitInt(e)}             &&\text{\it emit internal event}\\
     \N6&&&\ceu{\Break}                  &&\text{\it loop escape}\\
     \N7&&&\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}} &&\text{\it conditional}\\
     \N8&&&\ceu{\stmt_1\,;\,\stmt_2}     &&\text{\it sequence}\\
     \N9&&&\ceu{\Loop \stmt}             &&\text{\it infinite loop}\\
  \N{10}&&&\ceu{\Every{e}\,\stmt}        &&\text{\it event iteration}\\
  \N{11}&&&\ceu{\stmt_1\ParAnd\stmt_2}   &&\text{\it par/and statement}\\
  \N{12}&&&\ceu{\stmt_2\ParOr\stmt_2}    &&\text{\it par/or statement}\\
  \N{13}&&&\ceu{\Fin\stmt}               &&\text{\it finalization statement}\\
  \N{14}&&&\ceu{\Nop}                    &&\text{\it dummy statement}\\
  \N{15}&&&\ceu{\RunAt(n)}               &&\text{\it run at stack level~$n$}\\
  \N{16}&&&\ceu{\Rest(n)}                &&\text{\it restore environment}\\
  \N{17}&&&\ceu{\stmt_1\AtLoop\stmt_2}   &&\text{\it unwinded loop}\\
  \N{18}&&&\ceu{\stmt_1\AtParAnd\stmt_2} &&\text{\it unwinded par/and}\\
  \N{19}&&&\ceu{\stmt_1\AtParOr\stmt_2}  &&\text{\it unwinded par/or}
\end{empheq}
\endgroup
\caption{The statements of basic \CEU.}
\label{fig.sem.syntax}
\end{figure}

For simplicity, we only consider integer expressions.  These are build up
from integer constants and variables by the usual mathematical operators
($+$, $-$, $\le$, \ldots).  We assume that expression evaluation takes zero
time (in accordance with the synchronous hypothesis) and that it always
produces an integer value.  In places where a boolean value is expected, any
nonzero value means true while zero means false.

We distinguish between three kinds of basic \CEU statements.  First, there
are those statements which are common in imperative languages and behave as
usual, namely, blocks, assignments, conditionals, sequences, loops, and
breaks.  The $\ceu{\Block}$ statement of basic \CEU introduces its local
variables at once in a list of identifiers.

The statements of the second kind are those which are specific to \CEU.
These are the statements $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\EmitInt}$, and $\ceu{\Every}$, which deal with events, the statements
$\ceu{\ParAnd}$ and~$\ceu{\ParOr}$, which define parallel compositions, and
the statement~$\ceu{\Fin}$, which defines a finalization block.  These basic
\CEU statements are more or less equivalent to their counterparts in full
\CEU.  We defer a precise description of their behavior and entailed
properties to Section~\ref{sec.sem.opsem}.

Finally, the statements of the third kind are the remaining ones, namely,
$\ceu{\Nop}$, $\ceu{\RunAt}$, $\ceu{\Rest}$, $\ceu{\AtLoop}$,
$\ceu{\AtParAnd}$, and~$\ceu{\AtParOr}$.  These are hidden statements used
by the interpreter to encode in the program's text information about its
execution.  We will have more to say about these \texttt{@}-statements in
Section~\ref{sec.sem.opsem}.  Before that, however, we need to present the
syntactical restrictions of basic \CEU and discuss the mapping of full \CEU
programs into basic \CEU programs.

\subsection{Syntactic Restrictions of Basic \CEU}
\label{sec.sem.restrictions}

The syntax of basic \CEU shown in Figure~\ref{fig.sem.syntax} can be seen as
a schema for generating programs.  Not all programs generated by this schema
are well-formed though.  To be considered a \emph{well-formed} basic \CEU
program, the generated program must satisfy the following restrictions:
\begin{enumerate}
\item\label{sec.sem.restrictions.1} If variable~$v$ occurs in an expression
  or assignment statement of the program, then this occurrence happens in
  the body of a~$\ceu{\Block}$ that declares~$v$.
\item\label{sec.sem.restrictions.2} If a~$\ceu{\Break}$ occurs in the
  program, then this occurrence happens in the body of a~$\ceu{\Loop}$.
\item\label{sec.sem.restrictions.3} If a statement of the
  form~$\ceu{\Loop{\stmt}}$ occurs in the program, then all execution paths
  within~$\stmt$ contain a matching~$\ceu{\Break}$ or an~$\ceu{\AwaitExt}$
  or an~$\ceu{\Every}$.
\item\label{sec.sem.restrictions.4} If a statement of the
  form~$\ceu{\Every{e}\,{\stmt}}$ or~$\ceu{\Fin{\stmt}}$ occurs in the
  program, then~$\stmt$ does not contain occurrences of $\ceu{\Loop}$,
  $\ceu{\Break}$, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, $\ceu{\Every}$,
  or~$\ceu{\Fin}$.
\end{enumerate}

\fs{Também não faz sentido eles terem parand e paror (mas acho que nao afeta
  as provas).}

\gl{Não adicionei parand/or na restrição porque de fato não precisa, mas
  fique à vontade para adicionar.}

Restrictions~\ref{sec.sem.restrictions.1} and~\ref{sec.sem.restrictions.2}
prevent the use of undeclared variables or orphan~$\ceu{\Break}$'s.
Restriction~\ref{sec.sem.restrictions.3} ensures that the program does not
have an infinite loop with a body that runs in zero time (which violates the
synchronous hypothesis).  And restriction~\ref{sec.sem.restrictions.4}
ensures that the body of $\ceu{\Every}$ and~$\ceu{\Fin}$ statements always
execute to completion within the same reaction.  Similar restrictions exist
in full \CEU, as discussed in Section~\ref{sec.ceu}.

From now on, whenever we speak of a basic \CEU program we mean a well-formed
basic \CEU program.

\fs{A restrição do fin não é por ser blocking point, pelo contrário.  Uma
  vez que ele começa a executar, ele tem que terminar na mesma reação pois a
  trilha tem que morrer pro programa continuar.}

\fs{A restrição do every também não tem a ver com ser blocking point. O
  bloco do every também precisa terminar na mesma reação pro every não
  perder eventos.}

\fs{A única restrição que tem a ver com safe blocking point é não poder ter
  break dentro de every.}

\gl{Veja se agora está OK.}

\subsection{From Full \CEU to Basic \CEU}
\label{sec.sem.concrete}

Most statements of full \CEU are also present in basic \CEU.  These shared
statements, however, are not exactly equivalent.  It is sometimes the case
that a statement full \CEU (say~\code{await}) has more features than its
basic \CEU counterpart ($\ceu{\AwaitInt}$).  In this section, we discuss how
the extra features of full \CEU are implemented in basic \CEU.

\fs{Não gostei desse parágrafo. (1) foco duplo no @-stmt que é óbvio que
  está fora da comparação. (2) "It is often the case" dá a impressão que
  temos 100 casos, quando na verdade são casos claros e enumeráveis. (3) o
  \code{finalize} está sim presente como \code{fin} mas com diferenças
  notáveis.}

\gl{Veja se está melhor.}

\subsubsection*{Await and emit}

The \code{await} and \code{emit} primitives of full \CEU are slightly more
complex than those of basic \CEU, as they support communication of values
between them.

Figure~\ref{lst.await_emit} shows a translation that adds a variable to hold
the value being communicated.
%
The original full \CEU code in Listing~\ref{lst.await_emit.a} declares an
internal event \code{e} (ln~2) and has an \code{await} (ln~4) and an
\code{emit} (ln~10) that communicate the value~$1$ between the trails in
parallel.
%
The translation to basic \CEU in Listing~\ref{lst.await_emit.b} declares an
additional shared variable \code{e\_} (ln~1) to hold the emitted value
(ln~9) and which can be accessed by the awaking trail (ln~5).

External events require a similar translation, i.e., each event needs a
corresponding global variable shared between all awaiting trails.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.a},
]

event int e;
par/or do
  var int v = await e;

  <...>
with
  <...>

  emit e(1);
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.b},
]
var int e_;
event int e;
par/or do
  await e;
  var int v = e_;
  <...>
with
  <...>
  e_ = 1;
  emit e;
end
\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for \code{await} and \code{emit}. }
\label{lst.await_emit}
\end{figure}

\subsubsection*{First-class timers}

To add support for first-class timers to basic \CEU , we introduce a
\code{TIMER} input event, which notifies the passage of time, and two global
variables: \code{timer\_} which holds the elapsed time, and \code{delta\_}
which holds the residual time, initially set to 0.

Listing~\ref{lst.TIMER.b} shows the basic \CEU program resulting from the
translation of the two timers shown in Listing~\ref{lst.TIMER.a} (ln~1--11).
A timer first adds a (possibly) negative delta from the time it should await
(ln~1).  Then, it enters in a loop that awakes on every occurrence of
\code{TIMER} (ln~7) and decrements the time it should await (ln~8).  Each
iteration of the loop checks if the timer has expired (ln~3), and sets the
new delta, which may affect a timer in sequence.  The check happens before
the await because the timer may already start expired due to the residual
time.

\begin{figure}[!ht]
\begin{minipage}[t]{0.33\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.a},
]
await 10ms;









await 1ms;

\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.63\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.b},
]
var int tot_ = 10000 + delta_;
loop do
    if tot_ <= 0 then
        delta_ = tot_;
        break;
    end
    await TIMER;
    tot_ = tot_ - timer_;
end

var int tot_ = 1000 + delta_;
<...> // same loop as above
\end{lstlisting}
\end{minipage}
\caption{ Full-to-Basic translation for timers. }
\label{lst.TIMER}
\end{figure}

\subsubsection*{Finalization}

% \begin{comment}
% Finally, a ``\code{finalize $A$ with $B$ end; $C$}'' in the concrete
% language is equivalent to ``\ceu{A;\;((\Fin{B})\ \Or\ C)}'' in the abstract
% language.  In the concrete language, $A$ and~$C$ execute in sequence, and
% the finalization code~$B$ is implicitly suspended waiting for~$C$
% to terminate.  In the abstract language, ``$\ceu{\Fin B}$'' suspends forever
% when reached (it is an awaiting statement that never awakes).  Hence, we
% need an explicit \code{or} to execute~$C$ in parallel, whose termination
% aborts ``$\ceu{\Fin B}$'', which finally causes~$B$ to execute (by the
% semantic rules below).
% \end{comment}

The biggest mismatch between full \CEU and basic \CEU is in their support
for finalization, i.e., between the statements \code{finalize} of full \CEU
and $\ceu{\Fin}$ of basic \CEU.
%
Listing~\ref{3.lst.fin.a} shows a full \CEU program containing an explicit
block (ln~1--8) that executes the statements in \code{<A>} (ln~3) immediately
followed by \code{<C>} (ln~7), and unconditionally executes \code{<B>}
(ln~5) when the block terminates or aborts.
%
To simulate this behavior in basic \CEU we need to perform the translation
shown in Listing~\ref{3.lst.fin.b}.  The basic \CEU code also executes
\code{<A>} (ln~1) immediately followed by \code{<C>} (ln~5).  The difference
is that the basic \code{fin <B>} statement (ln~3) blocks the pending statement
forever, which only awakes and executes when it is aborted.  The
\code{par/or} (ln~2--6) serves this purpose since it allows \code{<C>} to
execute immediately and aborts the \code{fin} when terminating.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.a},
]
do
    finalize
        <A>
    with
        <B>
    end
    <C>
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.b},
]
<A>
par/or do
    fin <B>
with
    <C>
end


\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for finalization. }
\label{3.lst.fin}
\end{figure}

\subsection{Operational Semantics}
\label{sec.sem.opsem}

We proceed to formalize the operation of the basic \CEU interpreter.  Our
goal here is twofold.  First, we want to define a function~$\reaction$ that
describes precisely the operation steps taken by the interpreter to compute
a single reaction to an external event.  Second, we want to establish
(prove) some properties of this function.  In particular, we want to
establish that:
\begin{enumerate}
\item $\reaction$ is indeed a function: the same program will always react
  in the same way to a same external event (i.e., reactions are
  deterministic);
\item $\reaction$ is a total function: its computation always yields a
  result (i.e., reactions terminate); and
\item $\reaction$ can be computed by a linear bounded automaton: the amount
  of memory it uses never exceeds a fixed threshold which depends solely on
  the input program (i.e., reactions are memory-bounded).
\end{enumerate}

We will define $\reaction$ using a set of rules for a small-step operational
semantics~\cite{Plotkin-G-D-1981}.  These rules dictate how the internal
state of the basic \CEU interpreter progresses while it is computing a
reaction.  A snapshot of this internal state is called a \emph{description},
denoted~$\delta$, and consists of a quadruple~$\<\stmt,n,e,\theta>$ where
\begin{itemize}
\item $\stmt$ is a well-formed basic \CEU program;
\item $n$ is a nonnegative integer, called the stack level;
\item $e$ is an event identifier or the empty identifier~$\nil$;
  and
\item $\theta$ is a memory.
\end{itemize}

We will detail the precise meaning and purpose of the components of the
description in due course.  For now, the important thing is that the steps
taken by the interpreter to compute a reaction can be viewed as transitions
between descriptions.  The transitions are dictated by rules hardcoded in
the interpreter.  Each rule establishes that when the interpreter is in a
description~$\delta$ and certain criteria are met, then it will
\emph{transition} to a modified description~$\delta'$, in symbols,
\[
  \delta\trans\delta'.
\]
We call the description on the left-hand side of the symbol~$\trans$ the
\emph{input description}, and the one on its right-hand side the
\emph{output description}.

After transitioning to a modified description, the interpreter repeats the
rule-evaluation/transition process, and continues to do so until a final
description is reached.  This final description, called an \emph{irreducible
  description}, embodies the result of the reaction.

A full \emph{reaction} is thus defined as a sequence of the transitions of
the form
\[
  \delta_0\trans\delta_1\trans\cdots\trans\delta_f.
\]
The initial description~$\delta_0=\<\stmt_0,0,e,\theta_0>$ contains the
three inputs of the reaction: the text of the program at the beginning of
the reaction ($\stmt_0$), the event~$e$ to which the program must react, and
the memory~$\theta_0$ which holds the values of the variables used
in~$\stmt_0$ at the beginning of the reaction.  The final
description~$\delta_f=\<stmt_f,0,\nil,\theta_f>$ contains the two outputs of
the reaction: the text of the program at the end of the reaction ($\stmt_f$)
and the values of the variables used in~$\stmt_f$ at the end of the
reaction.  The output program~$\stmt_f$ and memory~$\theta_f$ will be used
by the interpreter as inputs in the next reaction.

We write~$\delta_0\trans[i]\delta_f$ to indicate that $\delta_0$ leads
to~$\delta_f$ after exactly~$i$ transitions, and we
write~$\delta_0\trans[*]\delta_f$ to indicate that it does so after an
unspecified but finite number of transitions.  Using this notation, we can
define function~$\reaction$ (the first part of our goal) as follows:
\[
  \reaction(\stmt_0,\theta_0,e)=\<\stmt_f,\theta_f>
\]
if, and only if,
\[
  \<\stmt_0,0,e,\theta_0>\trans[*]\<\stmt_f,0,\nil,\theta_f>,
\]
where~$\<\stmt_f,0,\nil,\theta_f>$ is an irreducible description.  Under
this definition, $\reaction$ will be deterministic, terminating, and
memory-bounded (the second part of goal) if relation~$\trans[*]$ happens to
be so.  That this is the case is a consequence of the way transitions are
defined, as we will see in Section~\ref{sec.proofs}.

\strut\fs{Parei aqui também.}

The next two sections, Sections~\ref{sec.sem.outermost}
and~\ref{sec.sem.nested}, give the rules for transitions.  There are two
types of transitions: \emph{outermost transitions} $\out$ and \emph{nested
  transitions} $\nst$.  Both are defined by rules of the form
\[
  \AxiomC{\strut condition$_1$}
  \AxiomC{\strut condition$_2$}
  \AxiomC{$\cdots$}
  \AxiomC{\strut condition$_n$}
  \QuaternaryInfC{$\delta\trans\delta'$}
  \DisplayProof
\]
which establish that a transition~$\delta\trans\delta'$ shall take place if
condition$_1$, condition$_2$, \dots, and condition$_n$ are all true.  If the
number of conditions is zero, then the line is omitted and the rule is
called an axiom.

\subsection{Outermost Transitions}
\label{sec.sem.outermost}

The rules \R{push} and \R{pop} for~$\out$ transitions are non-recursive
definitions that apply to the program as a whole.  These are the only rules
that manipulate the stack level---the component of descriptions that
determines the order of execution of internal reactions.
%%
\begin{gather*}
  \AxiomC{$e\ne\nil$}
  \UnaryInfC{$\<\stmt,n,e,\theta>\out\<\bcast(\stmt,e),n+1,\nil,\theta>$}
  \DisplayProof
  \Rtag{push}\\
  %%
  \AxiomC{$n>0$}
  \AxiomC{$\stmt=\ceu{\Nop}\lor\isblk(\stmt,n)$}
  \BinaryInfC{$\<\stmt,n,\nil,\theta>\out\<\stmt,n-1,\nil,\theta>$}
  \Rtag{pop}
  \DisplayProof
\end{gather*}

Rule \R{push} can be applied whenever there is a nonempty event in the input
description; it instantly broadcasts the event to the program, which means it:
\begin{enumerate*}[label=(\roman*)]
\item awakes (and consumes) any active $\ceu{\AwaitExt}$ or
  $\ceu{\AwaitInt}$ statements in the program (see $\bcast$ in
  Figure~\ref{fig.bcast});
\item creates a nested reaction by increasing the stack level; and
\item consumes the input event ($e$ becomes~$\nil$).
\end{enumerate*}
Rule \R{push} is the only rule that matches a nonempty event in the input
description.

Rule \R{pop} simply decreases the stack level by one; it can only be applied
if the program is blocked (see $\isblk$ in Figure~\ref{fig.isblocked}) or
terminated ($\stmt=\ceu{\Nop}$).  This condition ensures that an
$\ceu{\EmitInt}$ only resumes after its internal reaction completes and
blocks at the current stack level.

At the beginning of a reaction, an external event is emitted, which triggers
rule \R{push}, immediately raising the stack level to~1.  At the end of the
reaction, the program will block or terminate and successive applications of
rule~\R{pop} will lead to an irreducible description with this same program
at stack level~0.

\subsection{Nested Transitions}
\label{sec.sem.nested}

The~$\nst$ transitions have the general form
\[
\<\stmt,n,\nil,\theta>\nst\<\stmt',n,e,\theta'>.
\]
They do not affect the stack level and never have an emitted event as a
precondition.  The distinction between~$\out$ and~$\nst$ prevents rules
\R{push} and \R{pop} from matching and, consequently, from inadvertently
modifying the stack level before the nested reaction is over.

A complete reaction is a sequence of transitions
%%
\begin{align*}
  \<\stmt_0,0,e_\ext,\theta_0>\outpush
  {\Big[{\nst[*]}{\out}\Big]{*}}
  \null\mathbin{\nst[*]\outpop}\<\stmt_f,0,\nil,\theta_f>.
\end{align*}
%%
First, a~$\outpush$ starts a nested reaction at level~1.  Then, a series of
alternations between zero or more~$\nst$ transitions (nested reactions) and
a single~$\out$ transition (stack operation) takes place.  Finally, a
last~$\outpop$ transition decrements the stack level to~0 and terminates the
reaction.

We now give the rules for nested transitions.  Since these rules do not
affect the stack level, whenever convenient, we will omit the stack level in
the their definition.  Thus, in this section, we will sometimes write
descriptions as triples~$\<\stmt,e,\theta>$ with the tacit understanding
that there is a hidden integer for the stack level between the
components~$\stmt$ and~$e$.

\subsubsection*{Declarations and assignments}

There are three $\nst$ rules for dealing with variables: \R{block}, which
introduces a new block of declarations; \R{restore}, which makes a
previously introduced block go out of scope; and \R{assign}, which evaluates
an expression and assigns the resulting value to a variable.
%%
\begin{gather*}
  \<\ceu{\Block{\vars\,\stmt}},\nil,\theta>
  \nst\<\ceu{\stmt;\Rest(\left|\theta\right|)},\nil,\memdecl(\theta,\vars)>
  \Rtag{block}\\
  %%
  \<\ceu{\Rest(n)},\nil,\theta>
  \nst\<\ceu{\Nop},\nil,\memrest(\theta,n)>
  \Rtag{restore}\\
  %%
  \<\ceu{v\coloneqq{\expr}},\nil,\theta>
  \nst\<\ceu{\Nop},\nil,\memupdt(\theta,v,\eval(\theta,\expr))>
  \Rtag{assign}
\end{gather*}

\gl{Desisti de alinhar as regras e fazê-las caber nas colunas (missão
  impossível).  Estou pensando em mover todas as regras nst para uma figura
  separada abrangendo duas colunas, e alinhá-las lá talvez reduzindo a
  fonte.  Antes disso, porém, prefiro terminar o texto.  Se der tempo eu
  faço isso.  Se não der, submetemos do jeito que está (desalinhado mas
  correto) e resolvemos depois.  O que acha?}

The three rules, \R{block}, \R{restore}, and~\R{assign}, act on the input
memory~$\theta$.  A \emph{memory} is a stack of environments
$[E_1,\dots,E_k]$ where each environment~$E_i$ is a set of bindings, i.e.,
pairs of the form~$(v,n)$ which associate a variable~$v$ to an integer
value~$n$.  For instance, the memory
\[
  \big[\{(v_1,1),(v_2,\bot)\},\,\{(v_1,0)\}\big]
\]
has two environments: $E_1=\{(v_1,1),(v_2,\bot)\}$ (top-of-stack)
and~$E_2=\{(v_1,0)\}$.  This memory tells us that, at some point,
variable~$v_1$ was declared and set to~0, and that later, in a nested scope,
$v_1$ was re-declared (shadowing the previous declaration) and~$v_2$ was
declared for the first time.  Still in the nested scope, which corresponds
to the most recent environment~$E_1$, variable~$v_1$ was set to~1 but~$v_2$
remained undefined, hence its value~$\bot$ (\emph{undefined}).

We use the following functions to manipulate memories (all of them return a
modified memory):
\begin{align*}
  \memdecl(\theta,v_1,,\dots,v_n)
  &=\{(v_1,\bot),\dots,(v_n,\bot)\}:\theta\\
  %%
  \memrest(\theta,n)
  &=\text{pops $\left|\theta\right|-n$ elements from~$\theta$}\\
  %%
  \memupdt(E{:}\theta,v,n)
  &=\begin{cases}
    \begin{aligned}[b]
      &((E-\{(v,n')\})\\
      &\quad\null\cup\{(v,n)\}):\theta
    \end{aligned}
    &\text{if~$(v,n')\in{E}$}\\
    %%
    \memupdt(\theta,v,n)
    &\text{otherwise}
  \end{cases}
\end{align*}
%%
The colon ($:$) stands for the list constructor operator---thus $E{:}\theta$
denotes the stack obtained by pushing~$E$
onto~$\theta$---and~$\left|\theta\right|$ stands for the length of
stack~$\theta$.

Function~$\memdecl$ pushes onto stack~$\theta$ a new environment in which
variables~$v_1$, \dots, $v_n$ are declared but not initialized.
Function~$\memrest$ restores stack~$\theta$ to index~$n$, dropping any
environments above this index.  And function~$\memupdt$ binds variable~$v$
to the integer~$n$ in the most recent environment where~$v$ occurs.

Back to the rules, \R{block} transforms a statement of the form
$\ceu{\Block{\vars\,\stmt}}$ into a sequence
$\ceu{\stmt;\Rest(\left|\theta\right|)}$ and pushes onto~$\theta$ a new
environment declaring all variables in~$\vars$.  The idea is that
after~$\stmt$ executes and the block goes out of scope, the memory is
restored to its original length by the subsequent $\ceu{\Rest}$ statement
(rule~\R{restore}), which effectively removes any environments introduced by
the block and its body.

Rule~\R{assign} transforms~$\ceu{v\coloneqq\expr}$ into $\ceu{\Nop}$ (the
dummy statement) and performs the assignment.  That is, it evaluates~$\expr$
to an integer~$n$ and assigns~$n$ to variable~$v$ in the most recent
environment where~$v$ was declared.

Expression evaluation is carried out by function~$\memeval$.  For
simplicity, we assume that~$\memeval$ always returns an integer.  In
practice, any error in the evaluation, such as access to an uninitialized
variable or division by zero, will cause the interpreter to abort.

\subsubsection*{Emissions}

\begin{gather*}
  \<\ceu{\EmitInt(e)},n,\nil,\theta>
  \nst\<\ceu{\RunAt(n)},n,e,\theta>\Rtag{emit-int}\\
  %%
  \<\ceu{\RunAt(n)},n,\nil,\theta>
  \nst\<\ceu{\Nop},n,\nil,\theta>\Rtag{run-at}
\end{gather*}

An $\ceu{\EmitInt(e)}$ generates event $e$ and becomes a $\ceu{\RunAt(n)}$
statement (rule \R{emit-int}); this $\ceu{\RunAt(n)}$ statement only resumes
at stack level~$n$ (rule \R{run-at}).

Since every~$\nst$ rule expects the input event to be empty, an application
of \R{emit-int} leads immediately to an application of \R{push} at the outer
level, creating a new level~$n+1$ on the stack.  With this new stack level,
the $\ceu{\RunAt}(n)$ resulting from the $\ceu{\EmitInt(e)}$ can only
transition after future applications of~\R{pop} put the stack level back
in~$n$.  This interplay between \R{emit-int}, \R{push}, \R{pop}, and
\R{run-at} provides the desired stack-based semantics for internal events.

\subsubsection*{Conditionals}

\begin{gather*}
  \AxiomC{$\eval(\theta,\expr)\ne0$}
  \UnaryInfC{$\<\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}},\nil,\theta>
    \nst\<\stmt_1,\nil,\theta>$}
  \DisplayProof
  \Rtag{if-true}\\
  %%
  \AxiomC{$\eval(\theta,\expr)=0$}
  \UnaryInfC{$\<\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}},\nil,\theta>
    \nst\<\stmt_2,\nil,\theta>$}
  \DisplayProof
  \Rtag{if-false}
\end{gather*}

Rules \R{if-true} and \R{if-false} transform a conditional statement into
its if-part ($\stmt_1$) or else-part ($\stmt_2$) depending on the value to
which the associated expression ($\expr$) evaluates in the current memory.
If it evaluates to a nonzero value, then \R{if-true} applies and the
conditional becomes~$\stmt_1$; otherwise, \R{if-false} applies and the
conditional becomes~$\stmt_2$.  These are the only rules that use the
contents of the input memory in a way that affects the control flow.

\subsubsection*{Sequences}

\begin{gather*}
  \<\ceu{\Nop;\stmt_2},\nil,\theta>
  \nst\<\stmt_2,\nil,\theta>
  \Rtag{seq-nop}\\
  %%
  \<\ceu{\Break;\stmt_2},\nil,\theta>
  \nst\<\ceu{\Break},\nil,\theta>\Rtag{seq-brk}\\
  %%
  \AxiomC{$\<\stmt_1,\nil,\theta>\nst\<\stmt_1',e,\theta'>$}
  \UnaryInfC{$\<\ceu{\stmt_1;\stmt_2},\nil,\theta>
    \nst\<\ceu{\stmt_1';\stmt_2},e,\theta'>$}
  \DisplayProof
  \Rtag{seq-adv}
\end{gather*}

A sequence whose first part is terminated ($\ceu{\Nop}$) becomes its second
part (rule \R{seq-nop}).  A sequence whose first part is a~$\ceu{\Break}$,
propagates the~$\ceu{\Break}$ by dropping its second part (rule
\R{seq-brk}).  Finally, a sequence whose first part is neither $\ceu{\Nop}$
nor~$\ceu{\Break}$ advances to the sequence, event, and memory resulting
from advancing just its first part (rule \R{seq-adv}).

\subsubsection*{Loops}

\begin{gather*}
  \<\ceu{\Loop{\stmt}},\nil,\theta>
  \nst\<\ceu{(\stmt\AtLoop{\stmt});
    \Rest({\left|\theta\right|})},\nil,\theta>
  \Rtag{loop-expd}\\
  %% 
  \<\ceu{\Nop\AtLoop{\stmt_2}},\nil,\theta>
  \nst\<\ceu{\Loop{\stmt_2}},\nil,\theta>
  \Rtag{loop-nop}\\
  %%
  \<\ceu{\Break\AtLoop{\stmt_2}},\nil,\theta>
  \nst\<\ceu{\Nop},\nil,\theta>
  \Rtag{loop-brk}\\
  %%
  \AxiomC{$\<\stmt_1,\nil,\theta>\nst\<\stmt_1',e,\theta'>$}
  \UnaryInfC{$\<\ceu{\stmt_1\AtLoop{\stmt_2}},\nil,\theta>
    \nst\<\ceu{\stmt_1'\AtLoop{\stmt_2}},e,\theta'>$}
  \DisplayProof
  \Rtag{loop-adv}
\end{gather*}

When the interpreter encounters a $\ceu{\Loop}$, it expands its body in
sequence with the loop itself followed by a $\ceu{\Rest}$ statement (rule
\R{loop-expd}).  The $\ceu{\Rest}$ statement ensures that if the loop is
terminated by a $\ceu{\Break}$, any environments introduced by the loop are
popped from the memory.

The remaining rules for loops are similar to those for sequences but use
``\texttt{@}'' as separators to bind the current code of the loop to its
next iteration.  Rules \R{loop-nop} and \R{loop-adv} are analogous to rules
\R{seq-nop} and \R{seq-adv}.  They advance the current code of the loop
until it becomes a~$\ceu{\Nop}$.  When this happens the loop is restarted
(\R{seq-nop}).  Note that if we had used ``\texttt{;}'' as a separator in
loops, rules \R{loop-brk} and \R{seq-brk} would conflict.  Finally, rule
\R{loop-brk} escapes the enclosing loop, transforming everything into
a~$\ceu{\Nop}$.

\strut\gl{Até aqui está estável (não mexo mais antes da sua revisão).}

\subsubsection*{Par/and and par/or compositions}

\begin{align*}
  &\begin{aligned}[b]
    &\<\ceu{\stmt_1\And{\stmt_2}},n,\nil,\theta>\\[-1\jot]
    &\qquad\null\nst\<\ceu{\stmt_1\AtAnd(\RunAt(n);\stmt_2)},n,\nil,\theta>
  \end{aligned}
  \Rtag{and-expd}\\
  %%
  &\begin{aligned}[b]
    &\<\ceu{\stmt_1\Or{\stmt_2}},n,\nil,\theta>\\[-1\jot]
    &\qquad\null\nst\<\ceu{(\stmt_1\AtOr(\RunAt(n);\stmt_2));
      \Rest(\left|\theta\right|)},n,\nil,\theta>
  \end{aligned}
  \Rtag{or-expd}
\end{align*}

The rules for~$\ceu{\And}$ and~$\ceu{\Or}$ compositions ensure that their
left branch always transition before their right branch.

\begin{align*}
  &\AxiomC{$\<\stmt_1,\nil,\theta>\nst\<\stmt_1',e,\theta'>$}
  \UnaryInfC{$\<\ceu{\stmt_1\AtAnd{\stmt_2}},\nil,\theta>
    \nst\<\ceu{\stmt_1'\AtAnd{\stmt_2}},e,\theta'>$}
  \DisplayProof
  \Rtag{and-adv1}\\
  %%
  &\AxiomC{$\isblocked(\stmt_1,n)$}
  \AxiomC{$\<\stmt_2,n,\nil,\theta'>\nst\<\stmt_2',n,e,\theta'>$}
  \BinaryInfC{$\<\ceu{\stmt_1\AtAnd{\stmt_2}},n,\nil,\theta>
    \nst\<\ceu{\stmt_1\AtAnd{\stmt_2'}},n,e,\theta'>$}
  \DisplayProof
  \Rtag{and-adv2}
\end{align*}

\begin{align*}
  &\AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p'\AtOr{q}},n,e>$}
  \DisplayProof
  \Rtag{or-adv1}\\
  %%
  &\AxiomC{$\isblocked(p,n)$}
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \BinaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p\AtOr{q'}},n,e>$}
  \DisplayProof
  \Rtag{or-adv2}
\end{align*}

\def\JOT{.8\jot}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (p~and~q),n,\epsilon \RR \NST \LL (p~@and~(@canrun(n)~;~q)),n,\epsilon \RR
%     & \textbf{(and-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \NST \LL (p'~@and~q),n,e \RR }
%     & \textbf{(and-adv1)}      \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \RR \NST \LL (p~@and~q'), n, e \RR }
%     & \textbf{(and-adv2)}      \\
% %%%
% & \LL (p~or~q), n, \epsilon \RR \NST \LL (p~@or~(@canrun(n)~;~q)), n, \epsilon \RR
%     & \textbf{(or-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p'~@or~q), n, e \RR }
%     & \textbf{(or-adv1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p~@or~q'), n, e \RR }
%     & \textbf{(or-adv2)}   %\\
% \end{eqnarray*}
% }
%-

Rules~\R{and-expd} and~\R{or-expd} insert a~$\ceu{\CanRun(n)}$ at the beginning
of the right branch.
This ensures that~any $\ceu{\EmitInt}$ on the left branch, which eventually becomes
a~$\ceu{\CanRun(n)}$, resumes before the right branch starts.
%
The deterministic behavior of the semantics relies on the \emph{isblocked}
predicate (see Figure~\ref{fig.isblocked}) which is used in rules
\R{and-adv2} and \R{or-adv2}.
These rules require the left branch~$p$ to be blocked for the
right branch to transition from~$q$ to~$q'$.

In a parallel~$\ceu{\AtAnd}$, if one branch terminates, the composition becomes the other branch (rules \R{and-nop1} and
\R{and-nop2} below).
%
In a parallel~$\ceu{\AtOr}$, however, if one branch terminates, the
whole composition
terminates and~$\clear$ is called to finalize the aborted
branch (rules \R{or-nop1} and \R{or-nop2}).

\begingroup
\begin{gather*}
  \<\ceu{{\Nop}\AtAnd{q}},n,\nil>\nst\<q,n,\nil>\Rtag{and-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Nop}},n,\nil>\nst\<p,n,\nil>$}
  \DisplayProof
  \Rtag{and-nop2}\\[\JOT]
  %%
  \<\ceu{{\Nop}\AtOr{q}},n,\nil>\nst\<\clear(q),n,\nil>\Rtag{or-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Nop}},n,\nil>\nst\<\clear(p),n,\nil>$}
  \DisplayProof
  \Rtag{or-nop2}
\end{gather*}
\endgroup

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (@nop~@and~q), n, \epsilon \RR \NST \LL q,n,\epsilon \RR
%     & \textbf{(and-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~@nop), n, \epsilon \RR \NST \LL p,n,\epsilon \RR }
%     & \textbf{(and-nop2)}   \\
% %%%
% & \LL (@nop~@or~q), n, \epsilon \RR \NST \LL clear(q),n,\epsilon \RR
%     & \textbf{(or-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~@nop), n, \epsilon \RR \NST \LL clear(p),n,\epsilon \RR }
%     & \textbf{(or-nop2)}   %\\
% \end{eqnarray*}
% }
%-

The~$\clear$ function (see Figure~\ref{fig.clear}) concatenates all
active~$\ceu{\Fin}$ bodies of the branch being aborted, so that they execute before the
composition rejoins.

As there are no transition rules for~$\ceu{\Fin}$ statements,
 once reached, a $\ceu{\Fin}$ halts and will only be consumed
if its trail is aborted.  At this point, its body will
execute as a result of the~$\clear$ call.  The body of a~$\ceu{\Fin}$
statement always execute within a reaction.  This is due to a syntactic
restriction: $\ceu{\Fin}$ bodies cannot
contain awaiting statements (namely, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, or $\ceu{\Fin}$).

Finally, a~$\ceu{\Break}$ in one branch of a parallel escapes the closest
enclosing~$\ceu{\Loop}$, properly aborting the other branch with the~$\clear$
function:
%
\begingroup
\begin{gather*}
  \hskip-.5em
  \<\ceu{{\Break}\AtAnd{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{and-brk1}\\[\JOT]
  %%
  \hskip-.5em
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{and-brk2}\\[\JOT]
  %%
  \<\ceu{{\Break}\AtOr{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{or-brk1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{or-brk2}
\end{gather*}
\endgroup

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (break~@and~q), n, \epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(and-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~break), n, \epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(and-brk2)}   \\
% %%%
% & \LL (break~@or~q),n,\epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(or-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~break),n,\epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(or-brk2)}   %\\
% \end{eqnarray*}
% }
%-

A reaction eventually blocks in~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, $\ceu{\Fin}$, and~$\ceu{\CanRun}$ statements in parallel
trails.
%
Then, if none of the trails is blocked in~$\ceu{\CanRun}$, it means that the
program cannot advance in the current reaction.
%
However, $\ceu{\CanRun}$ statements can still resume at lower stack indexes
and will eventually resume in the current reaction (see rule \R{pop}).

\begin{figure}[h]
\small
\begin{gather*}
  \boxed{
    \begin{align*}
      %%
      %%-
      \shortintertext{\llap{(i)~}Function~$\bcast$:}
      %%-
      %%
      \bcast(\ceu{\AwaitExt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\AwaitInt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\Every{e}\ {p}},e)
      &=\ceu{p;\,\Every{e}\ {p}}\\[-1\jot]
      %%
      \bcast(\ceu{\CanRun(n)},e)
      &=\ceu{\CanRun(n)}\\[-1\jot]
      %%
      \bcast(\ceu{\Fin{p}},e)
      &=\ceu{\Fin{p}}\\[-1\jot]
      %%
      \bcast(\ceu{p;\,q},e)
      &=\ceu{\bcast(p,e);\,q}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtLoop{q}},e)
      &=\ceu{\bcast(p,e)\AtLoop{q}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtAnd{q}},e)
      &=\ceu{{\bcast(p,e)}\AtAnd{\bcast(q,e)}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtOr{q}},e)
      &=\ceu{{\bcast(p,e)}\AtOr{\bcast(q,e)}}\\[-1\jot]
      %%
      bcast(\_,e)
      &=\_\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
      \\[1\jot]
      %%
      %%-
      \shortintertext{\llap{(ii)~}Predicate~$\isblocked$:}
      %%-
      %%
      \isblocked(\ceu{\AwaitExt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\AwaitInt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\Every{e}\ {p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\CanRun(m)},n)
      &=(n>m)\\[-1\jot]
      %%
      \isblocked(\ceu{\Fin{p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{p;\,q},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtLoop{q}},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtAnd{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtOr{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\_,n)
      &=\mathit{false}\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
        \\[1\jot]
      %%
      %%-
      \shortintertext{\llap{(iii)~}Function~$\clear$:}
      %%-
      %%
      \clear(\ceu{\AwaitExt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\AwaitInt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Every{e}\ p})
      %%
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\CanRun(n)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Fin{p}})
      &=p\\[-1\jot]
      %%
      \clear(\ceu{p;\,q})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtLoop{q}})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtAnd{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\ceu{p\AtOr{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\_)
      &=\xi\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
    \end{align*}}
\end{gather*}
\vskip-2\belowdisplayskip
\caption{%
  (i)~Function~$\bcast$ awakes awaiting trails matching the event by
  converting~$\ceu{\protect\AwaitExt}$ and~$\ceu{\protect\AwaitInt}$
  to~$\ceu{\protect\Nop}$, and by unwinding $\ceu{\protect\Every}$
  statements.
  %%
  \space(ii)~Predicate~$\isblocked$ is true only if all branches in parallel
  are blocked waiting for events, finalization clauses, or certain
  stack levels.
  %%
  \space(iii)~Function~$\clear$ extracts~$\ceu{\protect\Fin}$ statements in
  parallel and put their bodies in sequence.
  %%
  In~(i), (ii), and~(iii),~``$\_$'' denotes the omitted cases and~``$\xi$''
  denotes the empty string.
  %%
}
\label{fig.bcast}
\label{fig.isblocked}
\label{fig.clear}
\end{figure}

\subsection{A Complete Example}

\gl{TODO: Reação usando as regras.}

%-
% {\small
% \begin{align*}
%   bcast(e, awaitExt(e)) &= @nop                         \\
%   bcast(e, awaitInt(e)) &= @nop                         \\
%   bcast(e, every~e~p)   &= p;~every~e~p                 \\
%   bcast(e, @canrun(n))  &= @canrun(n)                   \\
%   bcast(e, fin~p)       &= fin~p                        \\
%   bcast(e, p~;~q)       &= bcast(e,p)~;~q               \\
%   bcast(e, p~@loop~q)   &= bcast(e,p)~@loop~q           \\
%   bcast(e, p~@and~q)    &= bcast(e,p)~@and~bcast(e,q)   \\
%   bcast(e, p~@or~q)     &= bcast(e,p)~@or~bcast(e,q)    \\
%   bcast(e, \_)          &= \bot \2 (mem,emitInt,break,if,  \\
%                                  & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-

%
%-
% {\small
% \begin{align*}
%   isblocked(n, \1 awaitExt(id)) &= true                                   \\
%   isblocked(n, \1 awaitInt(id)) &= true                                   \\
%   isblocked(n, \1 every~e~p)    &= true                                   \\
%   isblocked(n, \1 @canrun(m))   &= (n > m)                                \\
%   isblocked(n, \1 fin~p)        &= true                                   \\
%   isblocked(n, \1 p~;~q)        &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@loop~q)    &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@and~q)     &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 p~@or~q)      &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 \_)           &= false \2 (mem,emitInt,break,if,        \\
%                                 & \5\5\5\1 loop,and,or,@nop)   %\\
% \end{align*}
% }
%-

%-
% {\small
% \begin{align*}
%   clear( awaitExt(e) ) &= @nop                  \\
%   clear( awaitInt(e) ) &= @nop                  \\
%   clear( every~e~p )   &= @nop                  \\
%   clear( @canrun(n) )  &= @nop                  \\
%   clear( fin~p )       &= p                     \\
%   clear( p~;~q )       &= clear(p)              \\
%   clear( p~@loop~q )   &= clear(p)              \\
%   clear( p~@and~q )    &= clear(p)~;~clear(q)   \\
%   clear( p~@or~q )     &= clear(p)~;~clear(q)   \\
%   clear( \_ )          &= \bot \2 (mem,emitInt,break,if, \\
%                                   & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "index.tex"
%%% End:
