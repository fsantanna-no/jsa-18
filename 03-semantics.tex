\section{Formal Semantics of~\CEU}
\label{sec.sem}

We now introduce and formalize the semantics of a reduced version of \CEU,
called \emph{basic \CEU}.  Although simpler than the full language presented
in Section~\ref{sec.ceu}, basic \CEU is expressive enough to capture all the
essential characteristics of full \CEU, in particular, the stack-based
execution of internal events.  Once basic \CEU is defined, the more
elaborate constructs of full \CEU can be defined on top of it, as we will
discuss shortly.

The statements of basic \CEU are presented in Figure~\ref{fig.sem.syntax}.
In the figure, the metavariables~$v$ (ln~2), $e$ (ln~3--5, 10), and~$n$
(ln~15--16) range over variable identifiers, event identifiers, and
integers.  The metavariable~$\vars$ (ln~1) denotes zero or more variable
identifiers.  The metavariable~$\stmt$ (ln~1, 7--13, 17--19) denotes a
statement, i.e., any of the statements of
Figure~\ref{fig.sem.syntax}---complex statements are defined recursively in
terms of simpler statements.  Finally, the metavariable $\expr$ (ln~2, 7)
denotes an expression.

\gl{Outra opção para o basic seria usar o mesmo estilo do full mas colocar
  um $\upbeta$ no final.  E.g.,
  \lstinline[mathescape=true,keywords={block}]|block$_\upbeta$ ...|,
  \lstinline[mathescape=true,keywords={set}]|set$_\upbeta$ x:=y|,
  \lstinline[mathescape=true,keywords={seq}]|seq$_\upbeta$ x; y|,
  \lstinline[mathescape=true]|if$_\upbeta$...then...else...|,
  \lstinline[mathescape=true]|...par/and$_\upbeta$...|.  Assim daria para
  usar $\CEU_\upbeta$ (basic) e \CEU (full).}

\gl{Que tal ``local'' ao invés de ``block''?  Já que ``block'' também
  significa bloquear.}

\begin{figure}[ht!]
\begingroup
\setlength{\jot}{0pt}
\def\N#1{\mathllap{\text{\scriptsize{#1}}\hspace{1em}}}
\begin{empheq}[box=\fbox]{alignat*=3}
     \N1&\hskip4pt&&\ceu{\Block{\vars\ \stmt}}
                                    &\quad&\text{\it declaration block}\\
     \N2&&&\ceu{v\coloneqq\expr}         &&\text{\it assignment statement}\\
     \N3&&&\ceu{\AwaitExt(e)}            &&\text{\it await external event}\\
     \N4&&&\ceu{\AwaitInt(e)}            &&\text{\it await internal event}\\
     \N5&&&\ceu{\EmitInt(e)}             &&\text{\it emit internal event}\\
     \N6&&&\ceu{\Break}                  &&\text{\it loop escape}\\
     \N7&&&\ceu{\IfElse{\expr}{\stmt_1}{\stmt_2}} &&\text{\it conditional}\\
     \N8&&&\ceu{\stmt_1\,;\,\stmt_2}     &&\text{\it sequence}\\
     \N9&&&\ceu{\Loop \stmt}             &&\text{\it infinite loop}\\
  \N{10}&&&\ceu{\Every{e}\,\stmt}        &&\text{\it event iteration}\\
  \N{11}&&&\ceu{\stmt_1\ParAnd\stmt_2}   &&\text{\it par/and statement}\\
  \N{12}&&&\ceu{\stmt_2\ParOr\stmt_2}    &&\text{\it par/or statement}\\
  \N{13}&&&\ceu{\Fin\stmt}               &&\text{\it finalization statement}\\
  \N{14}&&&\ceu{\Nop}                    &&\text{\it dummy statement}\\
  \N{15}&&&\ceu{\RunAt(n)}               &&\text{\it run at stack level~$n$}\\
  \N{16}&&&\ceu{\Restore(n)}             &&\text{\it restore environment}\\
  \N{17}&&&\ceu{\stmt_1\AtLoop\stmt_2}   &&\text{\it unwinded loop}\\
  \N{18}&&&\ceu{\stmt_1\AtParAnd\stmt_2} &&\text{\it unwinded par/and}\\
  \N{19}&&&\ceu{\stmt_1\AtParOr\stmt_2}  &&\text{\it unwinded par/or}
\end{empheq}
\endgroup
\caption{The statements of basic \CEU.}
\label{fig.sem.syntax}
\end{figure}

For simplicity, we only consider integer expressions.  These are build up
from integer constants and variables by the usual mathematical operators
($+$, $-$, $\le$, \ldots).  We assume that expression evaluation takes zero
time (in accordance with the synchronous hypothesis) and that it always
produces an integer value.  In places where a boolean value is expected, any
nonzero value means true while zero means false.

We distinguish between three kinds of basic \CEU statements.  First, there
are those statements which are common in imperative languages and behave as
usual, namely, blocks, assignments, conditionals, sequences, loops, and
breaks.  The $\ceu{\Block}$ statement of basic \CEU introduces its local
variables at once in a list of identifiers.

The statements of the second kind are those which are specific to \CEU.
These are the statements~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\EmitInt}$, and~$\ceu{\Every}$, which deal with events, the
statements~$\ceu{\ParAnd}$ and~$\ceu{\ParOr}$, which define parallel
compositions, and the statement~$\ceu{\Fin}$, which defines a finalization
block.  These basic \CEU statements are more or less equivalent to their
counterparts in full \CEU.  We defer a precise description of their behavior
and entailed properties to Section~\ref{sec.sem.opsem}.

Finally, the statements of the third kind are the remaining ones, namely,
$\ceu{\Nop}$, $\ceu{\RunAt}$, $\ceu{\Restore}$, $\ceu{\AtLoop}$,
$\ceu{\AtParAnd}$, and~$\ceu{\AtParOr}$.  These are hidden statements used
by the interpreter to encode in the program's text information about its
execution.  We will have more to say about these \texttt{@}-statements in
Section~\ref{sec.sem.opsem}.  Before that, however, we need to present the
syntactical restrictions of basic \CEU and discuss the mapping of full \CEU
programs into basic \CEU programs.

\subsection{Syntactic Restrictions of Basic \CEU}
\label{sec.sem.restrictions}

The syntax of basic \CEU shown in Figure~\ref{fig.sem.syntax} can be seen as
a schema for generating programs.  Not all programs generated by this schema
are well-formed though.  To be considered a \emph{well-formed} basic \CEU
program, the generated program must satisfy the following restrictions:
\begin{enumerate}
\item\label{sec.sem.restrictions.1} If variable~$v$ occurs in an expression
  or assignment statement of the program, then this occurrence happens in
  the body of a~$\ceu{\Block}$ that declares~$v$.
\item\label{sec.sem.restrictions.2} If a~$\ceu{\Break}$ occurs in the
  program, then this occurrence happens in the body of a~$\ceu{\Loop}$.
\item\label{sec.sem.restrictions.3} If a statement of the
  form~$\ceu{\Loop{\stmt}}$ occurs in the program, then all execution paths
  within~$\stmt$ contain a matching~$\ceu{\Break}$ or an~$\ceu{\AwaitExt}$
  or an~$\ceu{\Every}$.
\item\label{sec.sem.restrictions.4} If a statement of the
  form~$\ceu{\Every{e}\,{\stmt}}$ or~$\ceu{\Fin{\stmt}}$ occurs in the
  program, then~$\stmt$ does not contain occurrences of $\ceu{\Loop}$,
  $\ceu{\Break}$, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, $\ceu{\Every}$,
  or~$\ceu{\Fin}$.
\end{enumerate}

\fs{Também não faz sentido eles terem parand e paror (mas acho que nao afeta
  as provas).}

\gl{Não adicionei parand/or na restrição porque de fato não precisa, mas
  fique à vontade para adicionar.}

Restrictions~\ref{sec.sem.restrictions.1} and~\ref{sec.sem.restrictions.2}
prevent the use of undeclared variables or orphan~$\ceu{\Break}$'s.
Restriction~\ref{sec.sem.restrictions.3} ensures that the program does not
have an infinite loop with a body that runs in zero time (which violates the
synchronous hypothesis).  And restriction~\ref{sec.sem.restrictions.4}
ensures that the body of $\ceu{\Every}$ and~$\ceu{\Fin}$ statements always
execute to completion within the same reaction.  Similar restrictions exist
in full \CEU, as discussed in Section~\ref{sec.ceu}.

From now on, whenever we speak of a basic \CEU program we mean a well-formed
basic \CEU program.

\fs{A restrição do fin não é por ser blocking point, pelo contrário.  Uma
  vez que ele começa a executar, ele tem que terminar na mesma reação pois a
  trilha tem que morrer pro programa continuar.}

\fs{A restrição do every também não tem a ver com ser blocking point. O
  bloco do every também precisa terminar na mesma reação pro every não
  perder eventos.}

\fs{A única restrição que tem a ver com safe blocking point é não poder ter
  break dentro de every.}

\gl{Veja se agora está OK.}

\subsection{From Full \CEU to Basic \CEU}
\label{sec.sem.concrete}

Most statements of full \CEU are also present in basic \CEU.  These shared
statements, however, are not exactly equivalent.  It is sometimes the case
that a statement full \CEU (say~\code{await}) has more features than its
basic \CEU counterpart ($\ceu{\AwaitInt}$).  In this section, we discuss how
the extra features of full \CEU are implemented in basic \CEU.

\fs{Não gostei desse parágrafo. (1) foco duplo no @-stmt que é óbvio que
  está fora da comparação. (2) "It is often the case" dá a impressão que
  temos 100 casos, quando na verdade são casos claros e enumeráveis. (3) o
  \code{finalize} está sim presente como \code{fin} mas com diferenças
  notáveis.}

\gl{Veja se está melhor.}

\subsubsection{\code{await} and \code{emit}}

The \code{await} and \code{emit} primitives of full \CEU are slightly more
complex than those of basic \CEU, as they support communication of values
between them.

Figure~\ref{lst.await_emit} shows a translation that adds a variable to hold
the value being communicated.
%
The original full \CEU code in Listing~\ref{lst.await_emit.a} declares an
internal event \code{e} (ln~2) and has an \code{await} (ln~4) and an
\code{emit} (ln~10) that communicate the value~$1$ between the trails in
parallel.
%
The translation to basic \CEU in Listing~\ref{lst.await_emit.b} declares an
additional shared variable \code{e\_} (ln~1) to hold the emitted value
(ln~9) and which can be accessed by the awaking trail (ln~5).

External events require a similar translation, i.e., each event needs a
corresponding global variable shared between all awaiting trails.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.a},
]

event int e;
par/or do
  var int v = await e;

  <...>
with
  <...>

  emit e(1);
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.await_emit.b},
]
var int e_;
event int e;
par/or do
  await e;
  var int v = e_;
  <...>
with
  <...>
  e_ = 1;
  emit e;
end
\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for \code{await} and \code{emit}. }
\label{lst.await_emit}
\end{figure}

\subsubsection{First-Class Timers}

To add support for first-class timers to basic \CEU , we introduce a
\code{TIMER} input event, which notifies the passage of time, and two global
variables: \code{timer\_} which holds the elapsed time, and \code{delta\_}
which holds the residual time, initially set to 0.

Listing~\ref{lst.TIMER.b} shows the basic \CEU program resulting from the
translation of the two timers shown in Listing~\ref{lst.TIMER.a} (ln~1--11).
A timer first adds a (possibly) negative delta from the time it should await
(ln~1).  Then, it enters in a loop that awakes on every occurrence of
\code{TIMER} (ln~7) and decrements the time it should await (ln~8).  Each
iteration of the loop checks if the timer has expired (ln~3), and sets the
new delta, which may affect a timer in sequence.  The check happens before
the await because the timer may already start expired due to the residual
time.

\begin{figure}[!ht]
\begin{minipage}[t]{0.33\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.a},
]
await 10ms;









await 1ms;

\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.63\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={lst.TIMER.b},
]
var int tot_ = 10000 + delta_;
loop do
    if tot_ <= 0 then
        delta_ = tot_;
        break;
    end
    await TIMER;
    tot_ = tot_ - timer_;
end

var int tot_ = 1000 + delta_;
<...> // same loop as above
\end{lstlisting}
\end{minipage}
\caption{ Full-to-Basic translation for timers. }
\label{lst.TIMER}
\end{figure}

\subsubsection{Finalization}

% \begin{comment}
% Finally, a ``\code{finalize $A$ with $B$ end; $C$}'' in the concrete
% language is equivalent to ``\ceu{A;\;((\Fin{B})\ \Or\ C)}'' in the abstract
% language.  In the concrete language, $A$ and~$C$ execute in sequence, and
% the finalization code~$B$ is implicitly suspended waiting for~$C$
% to terminate.  In the abstract language, ``$\ceu{\Fin B}$'' suspends forever
% when reached (it is an awaiting statement that never awakes).  Hence, we
% need an explicit \code{or} to execute~$C$ in parallel, whose termination
% aborts ``$\ceu{\Fin B}$'', which finally causes~$B$ to execute (by the
% semantic rules below).
% \end{comment}

The biggest mismatch between full \CEU and basic \CEU is in their support
for finalization, i.e., between the statements \code{finalize} of full \CEU
and $\ceu{\Fin}$ of basic \CEU.
%
Listing~\ref{3.lst.fin.a} shows a full \CEU program containing an explicit
block (ln~1--8) that executes the statements in \code{<A>} (ln~3) immediately
followed by \code{<C>} (ln~7), and unconditionally executes \code{<B>}
(ln~5) when the block terminates or aborts.
%
To simulate this behavior in basic \CEU we need to perform the translation
shown in Listing~\ref{3.lst.fin.b}.  The basic \CEU code also executes
\code{<A>} (ln~1) immediately followed by \code{<C>} (ln~5).  The difference
is that the basic \code{fin <B>} statement (ln~3) blocks the pending statement
forever, which only awakes and executes when it is aborted.  The
\code{par/or} (ln~2--6) serves this purpose since it allows \code{<C>} to
execute immediately and aborts the \code{fin} when terminating.

\begin{figure}[ht!]
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[
    numbers=right,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.a},
]
do
    finalize
        <A>
    with
        <B>
    end
    <C>
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[
    xleftmargin=1.75em,
    basicstyle=\ttfamily\small,
    caption={\,},
    label={3.lst.fin.b},
]
<A>
par/or do
    fin <B>
with
    <C>
end


\end{lstlisting}
\end{minipage}
%
\caption{Full-to-Basic translation for finalization. }
\label{3.lst.fin}
\end{figure}

\subsection{Operational Semantics}
\label{sec.sem.opsem}

We now proceed to formalize the operation of the basic \CEU interpreter.
Our goal here is twofold.  First, we want to define a function~$\reaction$
that describes precisely the operation steps taken by the interpreter to
compute a single reaction to an external input.  Second, we want to establish
(prove) some properties of this function.  In particular, we want to establish
that:
\begin{enumerate}
\item $\reaction$ is indeed a function: the same program will always react
  in the same way to a same external event (i.e., reactions are
  deterministic);
\item $\reaction$ is a total function: its computation always yields a
  result (i.e., reactions terminate); and
\item $\reaction$ can be computed by a linear bounded automaton: the amount
  of memory it uses never exceeds a fixed threshold which depends solely on
  the input program (i.e., reactions are memory-bounded).
\end{enumerate}

We will define $\reaction$ using a set of rules for an
small-step operational semantics~\cite{Plotkin-G-D-1981}.  These rules
dictate how the internal state of the basic \CEU interpreter progresses
while it is computing a reaction.  A snapshot of this internal state is
called a \emph{description}, denoted~$\delta$, and consists of a
quadruple~$\<\stmt,n,e,\theta>$ where
\begin{itemize}
\item $\stmt$ is a well-formed basic \CEU program;
\item $n$ is a nonnegative integer, called the \emph{stack level};
\item $e$ is an event identifier or the empty identifier~$\nil$;
  and
\item $\theta$ is a memory.
\end{itemize}

We will detail the precise meaning and purpose of the components of the
description in due course.  For now, the important thing is that the steps
taken by the interpreter to compute a reaction can be viewed as transitions
between descriptions.  The transitions are dictated by rules hardcoded in
the interpreter.  Each rule establishes that when the interpreter is in a
description~$\delta$ and certain criteria are met, then it will
\emph{transition} to a modified description~$\delta'$, in symbols,
\[
  \delta\trans\delta'.
\]
We call the description on the left-hand side of the symbol~$\trans$ the
\emph{input description}, and the one on its right-hand side the
\emph{output description}.

After transitioning to a modified description, the interpreter repeats the
rule-evaluation/transition process, and continues to do so until a final
description is reached.  This final description, called an \emph{irreducible
  description}, embodies the result of the reaction.

A full \emph{reaction} is thus defined as a sequence of the transitions of
the form
\[
  \delta_0\trans\delta_1\trans\cdots\trans\delta_f.
\]
The initial description~$\delta_0=\<\stmt_0,0,e,\theta_0>$ contains the
three inputs of the reaction: the text of the program at the beginning of
the reaction ($\stmt_0$), the event~$e$ to which the program must react, and
the memory~$\theta_0$ which holds the values of the variables used
in~$\stmt_0$ at the beginning of the reaction.  The final
description~$\delta_f=\<stmt_f,0,\nil,\theta_f>$ contains the two outputs of
the reaction: the text of the program at the end of the reaction ($\stmt_f$)
and the values of the variables used in~$\stmt_f$ at the end of the
reaction.  The output program~$\stmt_f$ and memory environment~$\theta_f$
will be used by the interpreter as inputs in the next reaction.

We write~$\delta_0\trans[i]\delta_f$ to indicate that $\delta_0$ leads
to~$\delta_f$ after exactly~$i$ transitions, and we
write~$\delta_0\trans[*]\delta_f$ to indicate that it does so after an
unspecified but finite number of transitions.  Using this notation, we can
define function~$\reaction$ (the first part of our goal) as follows:
\[
  \reaction(\stmt_0,\theta_0,e)=\<\stmt_f,\theta_f>
\]
if, and only if,
\[
  \<\stmt_0,0,e,\theta_0>\trans[*]\<\stmt_f,0,\nil,\theta_f>,
\]
where~$\<\stmt_f,0,\nil,\theta_f>$ is an irreducible description.  Under
this definition, $\reaction$ will be deterministic, terminating, and
memory-bounded (the second part of goal) if relation~$\trans[*]$ happens to
be so.  That this is the case is a consequence of the way transitions are
defined, as we will see in Section~\ref{sec.proofs}.

\strut\fs{Parei aqui também.}

The next two sections, Sections~\ref{sec.sem.outermost}
and~\ref{sec.sem.nested}, give the rules for transitions.  There are two
types of transitions: \emph{outermost transitions} $\out$ and \emph{nested
  transitions} $\nst$.  Both are defined by rules of the form
\[
  \AxiomC{\strut condition$_1$}
  \AxiomC{\strut condition$_2$}
  \AxiomC{$\cdots$}
  \AxiomC{\strut condition$_n$}
  \QuaternaryInfC{$\delta\trans\delta'$}
  \DisplayProof
\]
which establish that a transition~$\delta\trans\delta'$ shall take place if
condition$_1$, condition$_2$, \dots, and condition$_n$ are all true.  If the
number of conditions is zero, then the line is omitted and the rule is
called an axiom.

\subsection{Outermost Transitions}
\label{sec.sem.outermost}

The rules \R{push} and \R{pop} for~$\out$ transitions are non-recursive
definitions that apply to the program as a whole.  These are the only rules
that manipulate the stack level---the component of descriptions that
determines the order of execution of internal reactions.
%%
\begin{spreadlines}{\rulejot}
\begin{gather*}
  \AxiomC{$e\ne\nil$}
  \UnaryInfC{$\<\stmt,n,e,\theta>\out\<\bcast(\stmt,e),n+1,\nil,\theta>$}
  \DisplayProof
  \Rtag{push}\\
  %%
  \AxiomC{$n>0$}
  \AxiomC{$\stmt=\ceu{\Nop}\lor\isblocked(\stmt,n)$}
  \BinaryInfC{$\<\stmt,n,\nil,\theta>\out\<\stmt,n-1,\nil,\theta>$}
  \Rtag{pop}
  \DisplayProof
\end{gather*}
\end{spreadlines}

Rule \R{push} can be applied whenever there is a nonempty event in the input
description; it instantly broadcasts the event to the program, which means it:
\begin{enumerate*}[label=(\roman*)]
\item awakes any active $\ceu{\AwaitExt}$ or $\ceu{\AwaitInt}$ statements in
  the program (see $\bcast$ in Figure~\ref{fig.bcast});
\item creates a nested reaction by increasing the stack level; and
\item consumes the event ($e$ becomes~$\nil$).
\end{enumerate*}
Rule \R{push} is the only rule that matches (and consumes) a nonempty event
in the input description.

Rule \R{pop} simply decreases the stack level by one; it can only be applied
if the program is blocked (see $\isblocked$ in Figure~\ref{fig.isblocked})
or terminated ($\stmt=\ceu{\Nop}$).  This condition ensures that an
$\ceu{\EmitInt}$ only resumes after its internal reaction completes and
blocks at the current stack level.

At the beginning of a reaction, an external event is emitted, which triggers
rule \R{push}, immediately raising the stack level to~1.  At the end of the
reaction, the program will block or terminate and successive applications of
rule~\R{pop} will lead to a description with this same program at stack
level~0.

\subsection{Nested Transitions}
\label{sec.sem.nested}

All~$\nst$ transitions have the general form
\[
\<\stmt,n,\nil,\theta>\nst\<\stmt',n,e,\theta'>.
\]
That is, nested transitions do not affect the stack level and never have an
emitted event as a precondition.  The distinction between~$\out$ and~$\nst$
prevents rules \R{push} and \R{pop} from matching and, consequently, from
inadvertently modifying the current stack level before the nested reaction
is complete.

A complete reaction is a sequence of transitions
%%
\begin{align*}
  \<\stmt_0,0,e_\ext,\theta_0>\outpush
  \Big[\null\nst[*]\null\out\null\Big]\!\!\ast
  \null\nst[*]\null\outpop\<\stmt_f,0,\nil,\theta_f>.
\end{align*}
%%
First, a~$\outpush$ starts a nested reaction at level~1.  Then, a series of
alternations between zero or more~$\nst$ transitions (nested reactions) and
a single~$\out$ transition (stack operation) takes place.  Finally, a
last~$\outpop$ transition decrements the stack level to~0 and terminates the
reaction.

We now give the rules for nested transitions.  Since none of these rules
affect the stack level, we will omit it.  Thus, in this section, we will
write descriptions as triples~$\<\stmt,e,\theta>$ with the tacit
understanding that there is a hidden stack level~$n$ between the
components~$\stmt$ and~$e$.

\subsubsection*{Variable declaration}

Rule~\R{block} introduces a new block of variables and rule~\R{restore}
makes a previously introduced block go out of scope.

\begin{align*}
  &\<\ceu{\Block{\vars\,\stmt}},\nil,\theta>\\
  &\qquad\nst\<\ceu{\stmt\,;\,\Restore(\left|\theta\right|)},\nil,
    \memdcl(\theta,\vars)>
    \Rtag{block}\\[\rulejot]
  &\<\ceu{\Restore(m)},\nil,\theta>
    \nst\<\ceu{\Nop},\nil,\memrst(\theta,m)>
    \Rtag{restore}
\end{align*}

Both rules, \R{block} and \R{restore}, act on the input memory~$\theta$.  A
\emph{memory} is a stack of environments~$[E_1,\dots,E_k]$ where each
environment~$E_i$ consists of a set of bindings, i.e., pairs of the
form~$(v,n)$, which bind a variable~$v$ to an integer value~$n$.  For
instance, the memory
\[
  \big[\{(v_1,1),(v_2,\bot)\},\,\{(v_1,0)\}\big]
\]
has two environments: $E_1=\{(v_1,1),(v_2,\bot)\}$ (top-of-stack)
and~$E_2=\{(v_1,0)\}$.  This memory tells us that, at some point,
variable~$v_1$ was declared and set to~0, and that later, in a nested scope,
$v_1$ was re-declared (shadowing the previous declaration) and $v_2$ was
declared for the first time.  In the nested scope, which corresponds to the
most recent environment~$E_1$, variable~$v_1$ was set to~1 but~$v_2$
remained undefined---hence its value~$\bot$ (\emph{undefined}).

We use the following functions to manipulate memories (all of them return a
modified memory):
\begin{align*}
  \memdcl(\theta,v_1,,\dots,v_n)
  &=\{(v_1,\bot),\dots,(v_n,\bot)\}\mathbin{:}\theta\\
  %%
  \memrst(\theta,n)
  &=\text{pops $\left|\theta\right|-n$ elements from~$\theta$}\\
  %% 
  \memset(E:\theta,v,n)
  &=\begin{cases}
    ((E-\{(v,n')\})\cup(v,n)):\theta &\text{if~$(v,n')\in{E}$}\\
    \memset(\theta,v,n)              &\text{otherwise}
  \end{cases}
  %% 
  % \memget(E:\theta,v)
  % &=\begin{cases}
  %   n                 &\text{if $(v,n)\in{E}$}\\
  %   \memget(\theta,v) &\text{otherwise}
  % \end{cases}
\end{align*}
%%
where~`$:$' denotes the list constructor operator and~$\left|\theta\right|$
denotes the length of~$\theta$.  Function~$\memdcl$ declares...

Back to the rules,...

\gl{TODO: Terminar essa seção.}

\subsubsection*{Variable assignment}

\subsubsection*{Emit}

\subsubsection*{Conditionals}

\subsubsection*{Sequences and loops}

\subsubsection*{Parallel-and and parallel-or}

\def\JOT{.8\jot}

The~$\nst$ rules for atoms are defined as follows:
\begingroup
\def\JOT{-.1\jot}
\begin{align*}
  \<\ceu{\Mem(\Id)},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{mem}\\[\JOT]
  %%
  \<\ceu{\EmitInt(\Id)},n,\nil>
  &\nst\<\ceu{\CanRun(n)},n,\ceu{\Id}>\Rtag{emit-int}\\[\JOT]
  %%
  \<\ceu{\CanRun(n)},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{can-run}
\end{align*}
\endgroup

%-
% { \setlength{\jot}{20pt}
% \begin{align*}
% \LL mem(id), n, \epsilon \RR &\NST
% \LL @nop, n, \epsilon \RR
%     & \textbf{(mem)}        \\
% %%%
% \LL emit(id), n, \epsilon \RR &\NST
% \LL @canrun(n), n, id \RR
%     & \textbf{(emitInt)}    \\
% %%%
% \LL @canrun(n), n, \epsilon \RR &\NST
% \LL @nop, n, \epsilon \RR
%     & \textbf{(canrun)}     \\
% \end{align*}
% }
%-

A $\ceu{\Mem}$ operation becomes a $\ceu{\Nop}$ which indicates the memory
access (rule \R{mem}).
An $\ceu{\EmitInt(id)}$ generates an event $\ceu{\Id}$ and becomes a
$\ceu{\CanRun(n)}$ which can only resume at level~$n$ (rule \R{emit-int}).
Since all~$\nst$ rules can only be applied if $e=\nil$, an $\ceu{\EmitInt}$
inevitably causes rule \R{push} to execute at the outer level, creating a new
level~$n+1$ on the stack.
Also, with the new stack level, the resulting $\ceu{\CanRun}(n)$ itself cannot
transition yet (rule~\R{can-run}), providing the desired stack-based semantics for
internal events.

The rules for conditionals and sequences are the following:
\vskip-.6\baselineskip
\begingroup
\def\JOT{-.1\jot}
\begin{gather*}
  \AxiomC{$\eval(\ceu{\Mem(\Id)})$}
  \UnaryInfC{$\<\ceu{\IfElse{\Mem(\Id)}{p}{q}},n,\nil>\nst\<p,n,\nil>$}
  \DisplayProof
  \Rtag{if-true}\\[\JOT]
  %%
  \AxiomC{$\lnot\eval(\ceu{\Mem(\Id)})$}
  \UnaryInfC{$\<\ceu{\IfElse{\Mem(\Id)}{p}{q}},n,\nil>\nst\<q,n,\nil>$}
  \DisplayProof
  \Rtag{if-false}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\,;\,q},n,\nil>\nst\<\ceu{p';\,q},n,e>$}
  \DisplayProof
  \Rtag{seq-adv}\\[\JOT]
  \<\ceu{\Nop;\,q},n,\nil>\nst\<q,n,\nil>\Rtag{seq-nop}\\[\JOT]
  %%
  \<\ceu{\Break;\,q},n,\nil>\nst\<\ceu{\Break},n,\nil>\Rtag{seq-brk}
\end{gather*}
\endgroup
% \begin{align*}
%   \<\ceu{\Nop;\,q},n,\nil>&\nst\<q,n,\nil>\Rtag{seq-nop}\\[\JOT]
%   %%
%   \<\ceu{\Break;\,q},n,\nil>&\nst\<\ceu{\Break},n,\nil>\Rtag{seq-brk}
% \end{align*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \frac
%     { \DS val(id) \neq 0 }
% %   -----------------------------------------------------------
%     { \DS \LL (if~mem(id)~then~p~else~q),n,\epsilon \RR \NST
%           \LL p, n, \epsilon \RR }
%     & \textbf{(if-true)}       \\
% %%%
% & \frac
%     { \DS val(id,n) = 0 }
% %   -----------------------------------------------------------
%     { \DS \LL (if~mem(id)~then~p~else~q),n,\epsilon \RR \NST
%           \LL q,n,\epsilon \RR }
%     & \textbf{(if-false)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~;~q), n, \epsilon \RR \NST \LL (p'~;~q), n, e \RR }
%     & \textbf{(seq-adv)}      \\
% %%%
% & \LL (@nop~;~q),n,\epsilon \RR \NST  \LL q,n,\epsilon \RR
%     & \textbf{(seq-nop)}      \\
% %%%
% & \LL (break~;~q),n,\epsilon \RR \NST \LL break,n,\epsilon \RR
%     & \textbf{(seq-brk)}
% \end{eqnarray*}
% }
%-

Rules \R{if-true} and \R{if-false} are the only rules that use~$\ceu{\Mem}$
in a way that affects the control flow.
%
Function~$\eval$ evaluates a~$\ceu{\Mem}$ expression to a boolean value.
%
%Although the value here is arbitrary, it is unique in a reaction, because a
%given expression can execute only once within it (remember that $loops$ must
%contain $awaits$ which, from rule \textbf{await}, cannot awake in the same
%reaction they are reached).
%For all other rules, we omit these values (e.g., \textbf{seq-nop}).

%As determined for nested rules, compound expressions also can only have
%$\epsilon$ as a precondition and they never modify $n$.
%However, they can still emit an event to nest another reaction.
%For instance, in rule \textbf{seq-adv}, if the sub-expression $p$ emits event
%$e$, the whole composition also emits $e$.
%However, rules \textbf{push} and \textbf{pop} can only match at the outermost
%level.

The rules for loops are similar to those for sequences, but use ``\code{@}''
as separators to bind breaks to their enclosing loops:
\begin{align*}
  \<\ceu{\Loop{p}},n,\nil>
  &\nst\<\ceu{p\AtLoop{p}},n,\nil>\Rtag{loop-expd}\\[\JOT]
  %%
  &\hskip-6.35em
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \UnaryInfC{$\<\ceu{q\AtLoop{p}},n,\nil>\nst\<\ceu{q'\AtLoop{p}},n,e>$}
  \DisplayProof
  \Rtag{loop-adv}\\[\JOT]
  %%
  \<\ceu{\Nop\AtLoop{p}},n,\nil>
  &\nst\<\ceu{\Loop{p}},n,\nil>\Rtag{loop-nop}\\[\JOT]
  %%
  \<\ceu{\Break\AtLoop{p}},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{loop-brk}
\end{align*}

%-
% %
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (loop~p),n,\epsilon \RR \NST \LL (p~@loop~p), n, \epsilon \RR
%     & \textbf{(loop-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% % -----------------------------------------------------------
%     { \DS \LL (p~@loop~q),n,\epsilon \RR \NST \LL (p'~@loop~q), n, e \RR }
%     & \textbf{(loop-adv)}    \\
% %%%
% & \LL (@nop~@loop~p), n, \epsilon \RR \NST \LL (loop~p), n, \epsilon \RR
%     & \textbf{(loop-nop)}    \\
% %%%
% & \LL (break~@loop~p), n, \epsilon \RR \NST \LL @nop, n, \epsilon \RR
%     & \textbf{(loop-brk)}
% \end{eqnarray*}
% }
%-

When a program encounters a $\ceu{\Loop}$, it first expands its body in sequence with
itself (rule \R{loop-expd}).
Rules \R{loop-adv} and \R{loop-nop} are similar to rules
\R{seq-adv} and \R{seq-nop}, advancing the loop until a~$\ceu{\Nop}$ is reached.
However, what follows the loop is the loop itself (rule \R{loop-nop}).
Note that if we used ``\code{;}'' as a separator in loops, rules
\R{loop-brk} and \R{seq-brk} would conflict.
%
Rule \R{loop-brk} escapes the enclosing loop, transforming everything into
a~$\ceu{\Nop}$.
%Rule \textbf{loop-brk} escapes the enclosing loop, transforming everything
%into a $clear(p)$.
%We cannot simply transform the loop into a $nop$ because its body may be a
%parallel composition containing finalization blocks.

The rules for~$\ceu{\And}$ and~$\ceu{\Or}$ compositions ensure that their
left branch always transition before their right
branch:
%%
\begin{gather*}
  \hskip-.9em
  \<\ceu{p\And{q}},n,\nil>
  \nst\<\ceu{p\AtAnd(\CanRun(n);q)},n,\nil>
  \Rtag{and-expd}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\AtAnd{q}},n,\nil>\nst\<\ceu{p'\AtAnd{q}},n,e>$}
  \DisplayProof
  \Rtag{and-adv1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \BinaryInfC{$\<\ceu{p\AtAnd{q}},n,\nil>\nst\<\ceu{p\AtAnd{q'}},n,e>$}
  \DisplayProof
  \Rtag{and-adv2}\\[1.2\jot]
% \end{gather*}
% \begin{gather*}
  \<\ceu{p\Or{q}},n,\nil>
  \nst\<\ceu{p\AtOr(\CanRun(n);q)},n,\nil>
  \Rtag{or-expd}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p'\AtOr{q}},n,e>$}
  \DisplayProof
  \Rtag{or-adv1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \BinaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p\AtOr{q'}},n,e>$}
  \DisplayProof
  \Rtag{or-adv2}
\end{gather*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (p~and~q),n,\epsilon \RR \NST \LL (p~@and~(@canrun(n)~;~q)),n,\epsilon \RR
%     & \textbf{(and-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \NST \LL (p'~@and~q),n,e \RR }
%     & \textbf{(and-adv1)}      \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \RR \NST \LL (p~@and~q'), n, e \RR }
%     & \textbf{(and-adv2)}      \\
% %%%
% & \LL (p~or~q), n, \epsilon \RR \NST \LL (p~@or~(@canrun(n)~;~q)), n, \epsilon \RR
%     & \textbf{(or-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p'~@or~q), n, e \RR }
%     & \textbf{(or-adv1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p~@or~q'), n, e \RR }
%     & \textbf{(or-adv2)}   %\\
% \end{eqnarray*}
% }
%-

Rules~\R{and-expd} and~\R{or-expd} insert a~$\ceu{\CanRun(n)}$ at the beginning
of the right branch.
This ensures that~any $\ceu{\EmitInt}$ on the left branch, which eventually becomes
a~$\ceu{\CanRun(n)}$, resumes before the right branch starts.
%
The deterministic behavior of the semantics relies on the \emph{isblocked}
predicate (see Figure~\ref{fig.isblocked}) which is used in rules
\R{and-adv2} and \R{or-adv2}.
These rules require the left branch~$p$ to be blocked for the
right branch to transition from~$q$ to~$q'$.

In a parallel~$\ceu{\AtAnd}$, if one branch terminates, the composition becomes the other branch (rules \R{and-nop1} and
\R{and-nop2} below).
%
In a parallel~$\ceu{\AtOr}$, however, if one branch terminates, the
whole composition
terminates and~$\clear$ is called to finalize the aborted
branch (rules \R{or-nop1} and \R{or-nop2}).

\begingroup
\begin{gather*}
  \<\ceu{{\Nop}\AtAnd{q}},n,\nil>\nst\<q,n,\nil>\Rtag{and-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Nop}},n,\nil>\nst\<p,n,\nil>$}
  \DisplayProof
  \Rtag{and-nop2}\\[\JOT]
  %%
  \<\ceu{{\Nop}\AtOr{q}},n,\nil>\nst\<\clear(q),n,\nil>\Rtag{or-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Nop}},n,\nil>\nst\<\clear(p),n,\nil>$}
  \DisplayProof
  \Rtag{or-nop2}
\end{gather*}
\endgroup

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (@nop~@and~q), n, \epsilon \RR \NST \LL q,n,\epsilon \RR
%     & \textbf{(and-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~@nop), n, \epsilon \RR \NST \LL p,n,\epsilon \RR }
%     & \textbf{(and-nop2)}   \\
% %%%
% & \LL (@nop~@or~q), n, \epsilon \RR \NST \LL clear(q),n,\epsilon \RR
%     & \textbf{(or-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~@nop), n, \epsilon \RR \NST \LL clear(p),n,\epsilon \RR }
%     & \textbf{(or-nop2)}   %\\
% \end{eqnarray*}
% }
%-

The~$\clear$ function (see Figure~\ref{fig.clear}) concatenates all
active~$\ceu{\Fin}$ bodies of the branch being aborted, so that they execute before the
composition rejoins.

As there are no transition rules for~$\ceu{\Fin}$ statements,
 once reached, a $\ceu{\Fin}$ halts and will only be consumed
if its trail is aborted.  At this point, its body will
execute as a result of the~$\clear$ call.  The body of a~$\ceu{\Fin}$
statement always execute within a reaction.  This is due to a syntactic
restriction: $\ceu{\Fin}$ bodies cannot
contain awaiting statements (namely, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, or $\ceu{\Fin}$).

Finally, a~$\ceu{\Break}$ in one branch of a parallel escapes the closest
enclosing~$\ceu{\Loop}$, properly aborting the other branch with the~$\clear$
function:
%
\begingroup
\begin{gather*}
  \hskip-.5em
  \<\ceu{{\Break}\AtAnd{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{and-brk1}\\[\JOT]
  %%
  \hskip-.5em
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{and-brk2}\\[\JOT]
  %%
  \<\ceu{{\Break}\AtOr{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{or-brk1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{or-brk2}
\end{gather*}
\endgroup

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (break~@and~q), n, \epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(and-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~break), n, \epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(and-brk2)}   \\
% %%%
% & \LL (break~@or~q),n,\epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(or-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~break),n,\epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(or-brk2)}   %\\
% \end{eqnarray*}
% }
%-

A reaction eventually blocks in~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, $\ceu{\Fin}$, and~$\ceu{\CanRun}$ statements in parallel
trails.
%
Then, if none of the trails is blocked in~$\ceu{\CanRun}$, it means that the
program cannot advance in the current reaction.
%
However, $\ceu{\CanRun}$ statements can still resume at lower stack indexes
and will eventually resume in the current reaction (see rule \R{pop}).

\begin{figure}[h]
\small
\begin{gather*}
  \boxed{
    \begin{align*}
      %%
      %%-
      \shortintertext{\llap{(i)~}Function~$\bcast$:}
      %%-
      %%
      \bcast(\ceu{\AwaitExt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\AwaitInt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\Every{e}\ {p}},e)
      &=\ceu{p;\,\Every{e}\ {p}}\\[-1\jot]
      %%
      \bcast(\ceu{\CanRun(n)},e)
      &=\ceu{\CanRun(n)}\\[-1\jot]
      %%
      \bcast(\ceu{\Fin{p}},e)
      &=\ceu{\Fin{p}}\\[-1\jot]
      %%
      \bcast(\ceu{p;\,q},e)
      &=\ceu{\bcast(p,e);\,q}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtLoop{q}},e)
      &=\ceu{\bcast(p,e)\AtLoop{q}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtAnd{q}},e)
      &=\ceu{{\bcast(p,e)}\AtAnd{\bcast(q,e)}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtOr{q}},e)
      &=\ceu{{\bcast(p,e)}\AtOr{\bcast(q,e)}}\\[-1\jot]
      %%
      bcast(\_,e)
      &=\_\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
      \\[1\jot]
      %%
      %%-
      \shortintertext{\llap{(ii)~}Predicate~$\isblocked$:}
      %%-
      %%
      \isblocked(\ceu{\AwaitExt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\AwaitInt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\Every{e}\ {p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\CanRun(m)},n)
      &=(n>m)\\[-1\jot]
      %%
      \isblocked(\ceu{\Fin{p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{p;\,q},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtLoop{q}},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtAnd{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtOr{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\_,n)
      &=\mathit{false}\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
        \\[1\jot]
      %%
      %%-
      \shortintertext{\llap{(iii)~}Function~$\clear$:}
      %%-
      %%
      \clear(\ceu{\AwaitExt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\AwaitInt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Every{e}\ p})
      %%
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\CanRun(n)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Fin{p}})
      &=p\\[-1\jot]
      %%
      \clear(\ceu{p;\,q})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtLoop{q}})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtAnd{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\ceu{p\AtOr{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\_)
      &=\xi\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
    \end{align*}}
\end{gather*}
\vskip-2\belowdisplayskip
\caption{%
  (i)~Function~$\bcast$ awakes awaiting trails matching the event by
  converting~$\ceu{\protect\AwaitExt}$ and~$\ceu{\protect\AwaitInt}$
  to~$\ceu{\protect\Nop}$, and by unwinding $\ceu{\protect\Every}$
  statements.
  %%
  \space(ii)~Predicate~$\isblocked$ is true only if all branches in parallel
  are blocked waiting for events, finalization clauses, or certain
  stack levels.
  %%
  \space(iii)~Function~$\clear$ extracts~$\ceu{\protect\Fin}$ statements in
  parallel and put their bodies in sequence.
  %%
  In~(i), (ii), and~(iii),~``$\_$'' denotes the omitted cases and~``$\xi$''
  denotes the empty string.
  %%
}
\label{fig.bcast}
\label{fig.isblocked}
\label{fig.clear}
\end{figure}

\subsection{Example}

\gl{TODO: Usar essa descrição como introdução para o exemplo.}

A complete reaction is a sequence of transitions:
%%
\begin{align*}
  \<\stmt_0,0,e_\ext,\theta_0>\outpush
  \Big[\null\nst[*]\null\out\null\Big]\!\!\ast
  \null\nst[*]\null\outpop\<\stmt_f,0,\nil,\theta_f>.
\end{align*}
%%
First, a~$\outpush$ starts a nested reaction at level~1.  Then, a series of
alternations between zero or more~$\nst$ transitions (nested reactions) and
a single~$\out$ transition (stack operation) takes place.  Finally, a
last~$\outpop$ transition decrements the stack level to~0 and terminates the
reaction.


%-
% {\small
% \begin{align*}
%   bcast(e, awaitExt(e)) &= @nop                         \\
%   bcast(e, awaitInt(e)) &= @nop                         \\
%   bcast(e, every~e~p)   &= p;~every~e~p                 \\
%   bcast(e, @canrun(n))  &= @canrun(n)                   \\
%   bcast(e, fin~p)       &= fin~p                        \\
%   bcast(e, p~;~q)       &= bcast(e,p)~;~q               \\
%   bcast(e, p~@loop~q)   &= bcast(e,p)~@loop~q           \\
%   bcast(e, p~@and~q)    &= bcast(e,p)~@and~bcast(e,q)   \\
%   bcast(e, p~@or~q)     &= bcast(e,p)~@or~bcast(e,q)    \\
%   bcast(e, \_)          &= \bot \2 (mem,emitInt,break,if,  \\
%                                  & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-

%
%-
% {\small
% \begin{align*}
%   isblocked(n, \1 awaitExt(id)) &= true                                   \\
%   isblocked(n, \1 awaitInt(id)) &= true                                   \\
%   isblocked(n, \1 every~e~p)    &= true                                   \\
%   isblocked(n, \1 @canrun(m))   &= (n > m)                                \\
%   isblocked(n, \1 fin~p)        &= true                                   \\
%   isblocked(n, \1 p~;~q)        &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@loop~q)    &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@and~q)     &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 p~@or~q)      &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 \_)           &= false \2 (mem,emitInt,break,if,        \\
%                                 & \5\5\5\1 loop,and,or,@nop)   %\\
% \end{align*}
% }
%-

%-
% {\small
% \begin{align*}
%   clear( awaitExt(e) ) &= @nop                  \\
%   clear( awaitInt(e) ) &= @nop                  \\
%   clear( every~e~p )   &= @nop                  \\
%   clear( @canrun(n) )  &= @nop                  \\
%   clear( fin~p )       &= p                     \\
%   clear( p~;~q )       &= clear(p)              \\
%   clear( p~@loop~q )   &= clear(p)              \\
%   clear( p~@and~q )    &= clear(p)~;~clear(q)   \\
%   clear( p~@or~q )     &= clear(p)~;~clear(q)   \\
%   clear( \_ )          &= \bot \2 (mem,emitInt,break,if, \\
%                                   & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "index.tex"
%%% End:
